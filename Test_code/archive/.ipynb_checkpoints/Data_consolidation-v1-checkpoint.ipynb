{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28663a3f-9544-457e-89df-e2425a87db28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import netCDF4 as nc\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import cdflib\n",
    "from scipy.interpolate import RBFInterpolator\n",
    "\n",
    "#Use this to ignore warning in inerpolation script, maybe get rid of later to check for other issues\n",
    "from warnings import simplefilter\n",
    "simplefilter(action=\"ignore\", category=pd.errors.PerformanceWarning)\n",
    "\n",
    "pd.set_option('display.max_columns', None) #Change settings in Pandas so it shows all columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4562cf-c783-45ff-ad57-b8c19f4011b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Constants\n",
    "R = 8.314 #kgm^2s^-2K^-1mol^-1\n",
    "h = 30 #Measurement height in m\n",
    "L = 2.5*10**3 #Latent heat of vapoization of water at 0 deg C [J/g], should try to calc based on dependency on C\n",
    "cp = 1005 #J/kg*K\n",
    "mm = 0.02896 #kg/mol molar mass dry air\n",
    "mm_w = 18.01 # molar mass of water [g/mol]\n",
    "CtoK = 273.15 #Conversion from Celcius to Kelvin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2450fbb9-9348-427a-b4f4-afbd6e93689d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in tower coords and set up dataframe\n",
    "tc = pd.read_csv('../Misc_data/tower_coords.csv') #datafrane of tower coordinates\n",
    "tc.set_index('Tower', inplace = True)\n",
    "\n",
    "#Convert lat and lon to coordinates in km, origin currently set to PFA coordinates, should change this since PFk is out of range\n",
    "tc['x'] = (tc.Lon - tc.Lon['PFA'])*111*np.cos(tc.Lat['PFA']*np.pi/180)\n",
    "tc['y'] = (tc.Lat - tc.Lat['PFA'])*111 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b6d0cc-e328-4c37-836e-b51947d8d818",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Functions\n",
    "\n",
    "#Func to convert RH to H2O concentration #fixthis - check if es calcs are correct\n",
    "def H2O_calc(TA, RH):\n",
    "    \n",
    "    #Convert T from Celcius to Kelvin\n",
    "    TA_K= TA + CtoK #Temperature [K]\n",
    "\n",
    "    es = 611.2*np.exp(17.67*(TA_K-CtoK)/(TA_K)) #Saturation vapor pressure [Pa] - Petty eqn 7.19 (pg 183)\n",
    "    e = es*RH/100 #Vapor pressure [Pa]\n",
    "    H2O = e/TA_K/R*mm_w #Water vapor concentration [g/m^3]\n",
    "    return H2O\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Interpolate TA at 2, 10, and 30 m\n",
    "\n",
    "def interpNSEW(data, interpdist = 1, interpdir = 'NSEW', kernel = 'thin_plate_spline'):\n",
    "    \n",
    "    #N, S, E, W coords (in km)\n",
    "    tc['y_N'] = tc['y'] + interpdist\n",
    "    tc['y_S'] = tc['y'] - interpdist\n",
    "    tc['x_E'] = tc['x'] + interpdist\n",
    "    tc['x_W'] = tc['x'] - interpdist\n",
    "\n",
    "    #Make a 2D array with x and y values for location of each tower\n",
    "    ar = np.array([tc.y.values, tc.x.values]).T\n",
    "    \n",
    "    #3D arrays of locations 1km up and down wind of each tower \n",
    "    #Dims are tower, time, and direction (x/y)\n",
    "    N_coords = np.stack((tc.x.values, tc.y_N.values)).T\n",
    "    S_coords = np.stack((tc.x.values, tc.y_S.values)).T\n",
    "    E_coords = np.stack((tc.x_E.values, tc.y.values)).T\n",
    "    W_coords = np.stack((tc.x_W.values, tc.y.values)).T\n",
    "\n",
    "\n",
    "    #Create dataframes to hold interpolated data at N, S, E, and W points\n",
    "    dat_N =pd.DataFrame(index = data.index, columns = data.columns)\n",
    "    dat_S =pd.DataFrame(index = data.index, columns = data.columns)\n",
    "    dat_E =pd.DataFrame(index = data.index, columns = data.columns)\n",
    "    dat_W =pd.DataFrame(index = data.index, columns = data.columns)\n",
    "\n",
    "\n",
    "    \n",
    "    for i in data.index:\n",
    "        dat_use = data.loc[data.index == i].values[0, :] #For each loop interpolate with just one row of data\n",
    "        nanmask = np.isfinite(dat_use)\n",
    "\n",
    "        if sum(nanmask)<10:\n",
    "            #Set N, S, E, W datapoints to nans if less than 10 (need to decide how to chose this number) values are available\n",
    "            \n",
    "            dat_N.loc[dat_N.index ==i] = np.nan# dat_S.loc[dat_S.index ==i] = dat_E.loc[dat_E.index ==i] = dat_W.loc[dat_W.index ==i] = np.nan;\n",
    "            \n",
    "\n",
    "        else:\n",
    "            dat_nn = dat_use[nanmask] #dat_use without nan values\n",
    "            ar_nn = ar[nanmask] #coordinates of towers that have finite values\n",
    "            # N_coords_nn = N_coords[nanmask]\n",
    "            dat_N.loc[dat_N.index ==i] = RBFInterpolator(ar_nn, dat_nn, kernel = kernel)(N_coords)\n",
    "            dat_S.loc[dat_S.index ==i] = RBFInterpolator(ar_nn, dat_nn, kernel = kernel)(S_coords)\n",
    "            dat_E.loc[dat_E.index ==i] = RBFInterpolator(ar_nn, dat_nn, kernel = kernel)(E_coords)\n",
    "            dat_W.loc[dat_W.index ==i] = RBFInterpolator(ar_nn, dat_nn, kernel = kernel)(W_coords)\n",
    "            \n",
    "    return dat_N, dat_S, dat_E, dat_W\n",
    "\n",
    "\n",
    "\n",
    "# Plot profiles \n",
    "\n",
    "#profile_plot(30_m_data, 10_m_data, 2_m_data, folder_for_plot_storage, x_axis_range)\n",
    "\n",
    "def profile_plot(data_1, data_2, data_3, folder, x_range = [-4, 4]):\n",
    "    data_mon_1 = data_1.groupby([data_1.index.month, data_1.index.time]).mean()\n",
    "    data_mon_2 = data_2.groupby([data_2.index.month, data_2.index.time]).mean()\n",
    "    data_mon_3 = data_3.groupby([data_3.index.month, data_3.index.time]).mean()\n",
    "    \n",
    "    \n",
    "    \n",
    "    for tower in tc.index:\n",
    "        \n",
    "        if towdat.z3 == 0:\n",
    "            pass\n",
    "        \n",
    "        else:\n",
    "\n",
    "            fig, axs = plt.subplots(12, 4, figsize = (10, 30))\n",
    "            for mon in range(6, 11):\n",
    "                i=0\n",
    "                for hour in data_mon_1.index.get_level_values(1).drop_duplicates():\n",
    "                    ax = axs[i//4, i%4]\n",
    "                    i= i+1\n",
    "                    \n",
    "                    dif_top = data_mon_1.loc[(mon, hour), tower] - data_mon_2.loc[(mon, hour), tower]\n",
    "                    dif_bottom = data_mon_3.loc[(mon, hour), tower] - data_mon_2.loc[(mon, hour), tower]\n",
    "                    # dif_bottom = data_mon[mon][hour][tower] - data_mon[mon][hour]tower]\n",
    "\n",
    "                    # ax.plot([df_mon.TA_1_1_1[mon][hour], df_mon.TA_1_2_1[mon][hour],df_mon.TA_1_3_1[mon][hour]], [towdat.z1, towdat.z2, towdat.z3])\n",
    "                    ax.plot([dif_top, 0, dif_bottom], [towdat.z1, towdat.z2, towdat.z3])\n",
    "                    ax.set_yticks([towdat.z3, towdat.z2, towdat.z1])\n",
    "                    ax.set_title(hour)\n",
    "                    ax.set_xlim(x_range)\n",
    "\n",
    "            fig.suptitle(tower)\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(str('./Outputs/diff_Profiles/Interp_dirs/' + folder + '/' +tower + '_TA_diff_profiles'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0feb10-94b0-4e7e-9cc4-44d71e0f26fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Collect data at 2, 10, and 30m for each tower\n",
    "\n",
    "#Fix tower height values #fixthis\n",
    "                                 \n",
    "# #Get dates to use as index from PFb data\n",
    "# filepath_i = tc.org_path['PFb'] #i for index because I am just using this to set the index\n",
    "# df_i\n",
    "\n",
    "#Create empty dataframes for 2, 10, and 30 m\n",
    "TA_2, TA_10, TA_30 = pd.DataFrame(), pd.DataFrame(), pd.DataFrame()\n",
    "RH_2, RH_10, RH_30 = pd.DataFrame(), pd.DataFrame(), pd.DataFrame()\n",
    "WS_top, WD, Ustar = pd.DataFrame(), pd.DataFrame(), pd.DataFrame()\n",
    "PA_top = pd.DataFrame()\n",
    "\n",
    "\n",
    "for tower in tc.index:\n",
    "    #print(tower)\n",
    "    towdat = tc.loc[tower] #Tower data\n",
    "    filepath = towdat.org_path #Eventually use gap-filled data for top level\n",
    "    df = pd.read_csv(filepath)\n",
    "    df = df.applymap(lambda x: np.nan if x == -9999 else x)\n",
    "    \n",
    "    \n",
    "    if tower == 'PFA': #Come back and get 30m data here later\n",
    "        TA_2[tower], TA_10[tower] = np.nan, np.nan\n",
    "        RH_2[tower], RH_10[tower] = np.nan, np.nan\n",
    "        # WS_top[tower], WD[tower], Ustar[tower] = np.nan, np.nan, np.nan\n",
    "        # PA_top = np.nan\n",
    "        \n",
    "        \n",
    "        #Read in PFA data\n",
    "        filepath = '../Misc_data/US-PFa_HR_201901010000_202001010000.csv' #This is hourly data -> need halfhourly to match up with other towers\n",
    "        PFA = pd.read_csv(filepath)\n",
    "\n",
    "        PFA = PFA.applymap(lambda x: np.nan if x == -9999 else x)\n",
    "        \n",
    "        \n",
    "        #Add datetime index\n",
    "        dt_ts = pd.to_datetime(PFA['TIMESTAMP_START'], format = '%Y%m%d%H%M') + dt.timedelta(minutes = 30) #half hour time stamp\n",
    "        PFA.set_index(dt_ts, inplace = True)\n",
    "\n",
    "\n",
    "        #Linear interpolate PFA data to 15 min and then use just min 15 and 45 timestamps\n",
    "        PFA_interp = PFA.resample('15T').mean().interpolate()\n",
    "        PFA_interp = PFA_interp[(PFA_interp.index.minute == 15) | (PFA_interp.index.minute == 45)]\n",
    "\n",
    "\n",
    "        #Cut to fit dates for the rest of the Cheesehead sites\n",
    "        startdate = dt.datetime(2019, 6, 1)\n",
    "        enddate = dt.datetime(2019, 11, 1)\n",
    "        PFA_interp = PFA_interp[startdate: enddate]\n",
    "\n",
    "        #Shift timestamps by 15 min to line up with other data \n",
    "        Corrected_TS_start = PFA_interp.index - dt.timedelta(minutes = 15)\n",
    "        PFA_interp.set_index(Corrected_TS_start, inplace = True)\n",
    "\n",
    "        #Add PFA 30 m data to dfs\n",
    "        TA_30['PFA'] = PFA_interp.TA_F_1_3_1 \n",
    "        RH_30['PFA'] = PFA_interp.RH_1_3_1\n",
    "        WS_top['PFA'] = PFA_interp.WS_1_3_1\n",
    "        WD['PFA'] = PFA_interp.WD_1_3_1\n",
    "        Ustar['PFA'] = PFA_interp.USTAR_1_3_1\n",
    "        PA_top['PFA'] = PFA_interp.PA_1_1_1 #Figure out a way to fill in later, only have pressure at top of tower, maybe use average across other towers\n",
    "\n",
    "        \n",
    "    \n",
    "    else:\n",
    "        #Add datetime index\n",
    "        dt_ts = pd.to_datetime(df['TIMESTAMP_START'], format = '%Y%m%d%H%M') \n",
    "        df.set_index(dt_ts, inplace = True)\n",
    "        \n",
    "        \n",
    "        #Add wind data to dfs\n",
    "        WS_top[tower] = df.WS_1_1_1\n",
    "        WD[tower] = df.WD_1_1_1\n",
    "        Ustar[tower] = df.USTAR_1_1_1\n",
    "        PA_top[tower] = df.PA_1_1_1\n",
    "        \n",
    "        #Towers with only one level\n",
    "        if towdat.z2 == towdat.z3 == 0:\n",
    "            TA_10[tower],  TA_30[tower] = np.nan, np.nan\n",
    "            TA_2[tower] = df.TA_1_1_1\n",
    "            \n",
    "            RH_10[tower],  RH_30[tower] = np.nan, np.nan\n",
    "            RH_2[tower] = df.RH_1_1_1\n",
    "            \n",
    "            \n",
    "        #Towers with two levels\n",
    "        elif towdat.z3 == 0:\n",
    "            TA_30[tower] = np.nan\n",
    "            TA_2[tower] = df.TA_1_2_1\n",
    "            TA_10[tower] = df.TA_1_1_1\n",
    "            \n",
    "            RH_30[tower] = np.nan\n",
    "            RH_2[tower] = df.RH_1_2_1\n",
    "            RH_10[tower] = df.RH_1_1_1\n",
    "            \n",
    "        #Towers with three levels    \n",
    "        else:\n",
    "            TA_30[tower] = df.TA_1_1_1\n",
    "            TA_10[tower] = df.TA_1_2_1\n",
    "            TA_2[tower] = df.TA_1_3_1\n",
    "            \n",
    "            RH_30[tower] = df.RH_1_1_1\n",
    "            RH_10[tower] = df.RH_1_2_1\n",
    "            RH_2[tower] = df.RH_1_3_1\n",
    "            \n",
    "            #For PFl, extrapolate 30m TA from 10 and 25m TA\n",
    "            if tower == 'PFl':\n",
    "                TA_30[tower] = df.TA_1_1_1 + (df.TA_1_1_1 - df.TA_1_2_1)/3 #/3 from 5/(25-10)\n",
    "                RH_30[tower] = df.RH_1_1_1 + (df.RH_1_1_1 - df.RH_1_2_1)/3 #/3 from 5/(25-10)\n",
    "\n",
    "                \n",
    "                \n",
    "#Convert RH to H2O concentration\n",
    "H2O_2 = H2O_calc(TA_2, RH_2)\n",
    "H2O_10 = H2O_calc(TA_10, RH_10)\n",
    "H2O_30 = H2O_calc(TA_30, RH_30)\n",
    "\n",
    "\n",
    "\n",
    "# #Add in PFA data after converting RH to H2O (because only H2O given in PFA dataset)\n",
    "\n",
    "# #Import data\n",
    "# filepath = '../Misc_data/US-PFa_HR_201901010000_202001010000.csv' #This is hourly data -> need halfhourly to match up with other towers\n",
    "# PFA = pd.read_csv(filepath)\n",
    "\n",
    "# PFA = PFA.applymap(lambda x: np.nan if x == -9999 else x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b373b171-a8d1-41e6-991f-ae7f91493921",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write this as function (hrz_NSEW_grad_calc) #fixthis\n",
    "#Might be better to have it be able to start with full TA, H2O dfs, parce into TA_2_N etc.\n",
    "\n",
    "#Interpolate TA and H2O\n",
    "TA_2_N, TA_2_S, TA_2_E, TA_2_W = interpfun(TA_2)\n",
    "TA_10_N, TA_10_S, TA_10_E, TA_10_W = interpfun(TA_10)\n",
    "TA_30_N, TA_30_S, TA_30_E, TA_30_W = interpfun(TA_30)\n",
    "\n",
    "H2O_2_N, H2O_2_S, H2O_2_E, H2O_2_W = interpfun(H2O_2)\n",
    "H2O_10_N, H2O_10_S, H2O_10_E, H2O_10_W = interpfun(H2O_10)\n",
    "H2O_30_N, H2O_30_S, H2O_30_E, H2O_30_W = interpfun(H2O_30)\n",
    "\n",
    "#Calculate gradients\n",
    "TA_30_NS = TA_30_N - TA_30_S\n",
    "TA_10_NS = TA_10_N - TA_10_S\n",
    "TA_2_NS = TA_2_N - TA_2_S\n",
    "\n",
    "TA_30_EW = TA_30_E - TA_30_W\n",
    "TA_10_EW = TA_10_E - TA_10_W\n",
    "TA_2_EW = TA_2_E - TA_2_W\n",
    "\n",
    "\n",
    "H2O_30_NS = H2O_30_N - H2O_30_S\n",
    "H2O_10_NS = H2O_10_N - H2O_10_S\n",
    "H2O_2_NS = H2O_2_N - H2O_2_S\n",
    "\n",
    "H2O_30_EW = H2O_30_E - H2O_30_W\n",
    "H2O_10_EW = H2O_10_E - H2O_10_W\n",
    "H2O_2_EW = H2O_2_E - H2O_2_W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e183e671-0bc4-46c2-bf81-337b00eeedff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combine TA and H2O into one dataframe\n",
    "#at some point check mesurement levels, might be 3m for one tower--how to handle?\n",
    "TA_all = pd.concat([TA_2, TA_10, TA_30], keys = [2, 10, 30])\n",
    "H2O_all = pd.concat([H2O_2, H2O_10, H2O_30], keys = [2, 10, 30])\n",
    "\n",
    "\n",
    "#Combine all TA and H2O data into a single dataframe \n",
    "\n",
    "TA_NS = pd.concat([TA_2_NS, TA_10_NS, TA_30_NS], keys = [2, 10, 30])\n",
    "TA_EW = pd.concat([TA_2_EW, TA_10_EW, TA_30_EW], keys = [2, 10, 30])\n",
    "\n",
    "H2O_NS = pd.concat([H2O_2_NS, H2O_10_NS, H2O_30_NS], keys = [2, 10, 30])\n",
    "H2O_EW = pd.concat([H2O_2_EW, H2O_10_EW, H2O_30_EW], keys = [2, 10, 30])\n",
    "\n",
    "TA_int_all = pd.concat([TA_NS, TA_EW], keys = ['NS', 'EW'])\n",
    "H2O_int_all = pd.concat([H2O_NS, H2O_EW], keys = ['NS', 'EW'])\n",
    "\n",
    "#Combine wind data into single dataframe\n",
    "wind_dat = pd.concat([WS_top, WD, Ustar], keys = ['WS_top', 'WD', 'Ustar'])\n",
    "\n",
    "#Save TA, H2O, wind data in pickles\n",
    "TA_all.to_pickle('./Outputs/TA_orig_all.pickle')\n",
    "H2O_all.to_pickle('./Outputs/H2O_orig_all.pickle')\n",
    "TA_int_all.to_pickle('./Outputs/TA_int_all.pickle')\n",
    "H2O_int_all.to_pickle('./Outputs/H2O_int_all.pickle')\n",
    "wind_dat.to_pickle('./Outputs/wind_dat.pickle') #fixthis rename to hrz_wind \n",
    "PA_top.to_pickle('./Outputs/PA_top.pickle')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6586967d-6e93-45cf-b208-04e5e95332d7",
   "metadata": {},
   "source": [
    "## Code Graveyard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1d561d-0d2a-44d4-b7f7-486295254dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #These should be the same as in Advection_calcs notebook, not needed here anymore\n",
    "# def WS_top_calc(tower, d_rat = 0.65):\n",
    "#     k = 0.4 #\n",
    "    \n",
    "#     #Measurement height (z1 for all towers except PFA)\n",
    "#     if tower == 'PFA':\n",
    "#         h_tow = tc.z3.loc[tower]\n",
    "#     else:\n",
    "#         h_tow = tc.z1.loc[tower]\n",
    "        \n",
    "#     h_veg = tc.veg_h.loc[tower] #Vegetation height\n",
    "#     WS_calc = (Ustar[tower]/k)*np.log((h_tow - d_rat*h_veg)/0.1*h_veg)\n",
    "#     return WS_calc\n",
    "    \n",
    "# def prof_calcs(tower, step = 0.1):\n",
    "#     towdat = tc.loc[tower] #Tower data\n",
    "    \n",
    "#     #Step is step size to be used for integration\n",
    "#     k = 0.4 #Von Karmann constant\n",
    "#     h_veg = tc.veg_h.loc[tower] #vegetation height\n",
    "#     h_tow = tc.z1.loc[tower] #tower height\n",
    "#     z_range = np.arange(0, h_tow + step, step)\n",
    "#     z_m = 0.1*h_veg #momentum friction parameter\n",
    "    \n",
    "#     d = 0.65*h_veg #zero plane displacement\n",
    "    \n",
    "#     # d_mean = h_tow - z_m*np.exp(k*WS_top[tower]/Ustar[tower])#zero plane displacement, mean of val calculated for all timestamps\n",
    "    \n",
    "    \n",
    "#     WS_prof = pd.DataFrame() #windspeed profile\n",
    "    \n",
    "#     T_grad_NS, T_grad_EW = pd.DataFrame(), pd.DataFrame()\n",
    "#     H2O_grad_NS, H2O_grad_EW = pd.DataFrame(), pd.DataFrame()\n",
    "    \n",
    "#     for z in z_range[::-1]:\n",
    "#         if z == h_tow:\n",
    "#             WS_prof[z] = WS_top[tower]\n",
    "#         elif z >= h_veg:\n",
    "#             pass\n",
    "#             # WS_prof[z] = Ustar[tower]/k*np.log((z-d)/z_m)\n",
    "#         else:\n",
    "#             pass\n",
    "            \n",
    "        \n",
    "#         if towdat.z3 == 0:\n",
    "#             pass\n",
    "#         else:\n",
    "#             #should maybe make this more flexible for different tower heights\n",
    "#             T_grad_slope_NS_up = (TA_30_NS[tower] - TA_10_NS[tower])/20 #Slope of temp gradient from 10 to 30 m, NS\n",
    "#             T_grad_slope_EW_up = (TA_30_EW[tower] - TA_10_EW[tower])/20 #Slope of temp gradient from 10 to 30 m, EW\n",
    "#             T_grad_slope_NS_low = (TA_10_NS[tower] - TA_2_NS[tower])/8 #Slope of temp gradient from 2 to 10 m, NS\n",
    "#             T_grad_slope_EW_low = (TA_10_EW[tower] - TA_2_EW[tower])/8 #Slope of temp gradient from 2 to 10 m, EW\n",
    "            \n",
    "#             H2O_grad_slope_NS_up = (H2O_30_NS[tower] - H2O_10_NS[tower])/20 #Slope of temp gradient from 10 to 30 m, NS\n",
    "#             H2O_grad_slope_EW_up = (H2O_30_EW[tower] - H2O_10_EW[tower])/20 #Slope of temp gradient from 10 to 30 m, EW\n",
    "#             H2O_grad_slope_NS_low = (H2O_10_NS[tower] - H2O_2_NS[tower])/8 #Slope of temp gradient from 2 to 10 m, NS\n",
    "#             H2O_grad_slope_EW_low = (H2O_10_EW[tower] - H2O_2_EW[tower])/8 #Slope of temp gradient from 2 to 10 m, EW\n",
    "            \n",
    "#             if z >= towdat.z2:\n",
    "#                 T_grad_NS[z] = TA_10_NS[tower] + T_grad_slope_NS_up*(z-towdat.z2)\n",
    "#                 T_grad_EW[z] = TA_10_EW[tower] + T_grad_slope_EW_up*(z-towdat.z2)\n",
    "                \n",
    "#                 H2O_grad_NS[z] = H2O_10_NS[tower] + H2O_grad_slope_NS_up*(z-towdat.z2)\n",
    "#                 H2O_grad_EW[z] = H2O_10_EW[tower] + H2O_grad_slope_EW_up*(z-towdat.z2)\n",
    "#             else:\n",
    "#                 T_grad_NS[z] = TA_10_NS[tower] - T_grad_slope_NS_low*(towdat.z2 - z)\n",
    "#                 T_grad_EW[z] = TA_10_EW[tower] - T_grad_slope_EW_low*(towdat.z2 - z)\n",
    "                \n",
    "#                 H2O_grad_NS[z] = TA_10_NS[tower] - H2O_grad_slope_NS_low*(towdat.z2 - z)\n",
    "#                 H2O_grad_EW[z] = TA_10_EW[tower] - H2O_grad_slope_EW_low*(towdat.z2 - z)\n",
    "\n",
    "                \n",
    "\n",
    "            \n",
    "#     return WS_prof, T_grad_NS, T_grad_EW, H2O_grad_NS, H2O_grad_EW\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843cb1b6-1feb-407a-b0f4-35a1a989eece",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Top only\n",
    "\n",
    "# #H and LE advection calcs\n",
    "\n",
    "# def hrz_ad_calc(tower):\n",
    "\n",
    "#     #Read in data\n",
    "#     df = pd.read_csv(tc.org_path.loc[tower])\n",
    "#     df = df.applymap(lambda x: np.nan if x == -9999 else x)\n",
    "\n",
    "#     #Add datetime index\n",
    "#     dt_ts = pd.to_datetime(df['TIMESTAMP_START'], format = '%Y%m%d%H%M') \n",
    "#     df.set_index(dt_ts, inplace = True)\n",
    "\n",
    "    \n",
    "#     PA_Pa = df.PA_1_1_1*1000 #kPa to Pa **this is at top of tower(~400m), need PA val for 30m and below**\n",
    "#     rho = mm*PA_Pa/df_TA_K.T/R #Dry air density at each tower [kg/m^3] **should probably use virtual temperature here** \n",
    "#     z = np.asarray(tc.z)[:, None] #Height of each tower\n",
    "\n",
    "\n",
    "#     #H advection\n",
    "#     H_SN = rho*z*cp*SN_wind*(T_i_S - T_i_N)/2000 #Advection of sensible heat by southerly wind [W/m^2]\n",
    "#     H_WE = rho*z*cp*WE_wind*(T_i_W - T_i_E)/2000 #Advection of sensible heat by westerly wind [W/m^2]\n",
    "#     H_ad = H_SN + H_WE #Total advection\n",
    "\n",
    "#     #LE advection\n",
    "#     LE_SN = z*L*SN_wind*(H2O_i_S - H2O_i_N)/2000 #Advection of latend heat by southerly wind [W/m^2]\n",
    "#     LE_WE = z*L*WE_wind*(H2O_i_W - H2O_i_E)/2000 #Advection of latent hear by westerly wind [W/m^2]\n",
    "\n",
    "#     LE_ad = (LE_SN + LE_WE)*rho/rho #LE advection (the *rho/rho just makes it a df with the same tower and timestamp as indices)\n",
    "\n",
    "\n",
    "#     hrz_ad = (H_ad + LE_ad).T\n",
    "#     #Deal with water vapor later\n",
    "#     # md_w = e/(R*TA_K) #Molar density of water vapor [mol/m^3], used in SLE calc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f48f52-4ea8-47d0-a479-523593d90316",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #H and LE advection calcs\n",
    "\n",
    "# def hrz_ad_calc(tower, step = 0.1):\n",
    "\n",
    "#     WS_prof, T_grad_NS, T_grad_EW, H2O_grad_NS, H2O_grad_EW = prof_calcs(tower, step)\n",
    "    \n",
    "#     TA_K = TA_30[tower] + CtoK\n",
    "    \n",
    "#     PA_Pa = PA_top[tower]*1000 #kPa to Pa **this is at top of tower(~400m), need PA val for 30m and below**\n",
    "#     rho = mm*PA_Pa/TA_K/R #Dry air density at each tower [kg/m^3] **should probably use virtual temperature here** \n",
    "#     z = step #np.asarray(tc.loc[tower].z1) #Height of each tower\n",
    "\n",
    "#     SN_wind = WS_prof*np.sin(WD[tower]*np.pi/180)\n",
    "#     WE_wind = WS_prof*np.cos(WD[tower]*np.pi/180)\n",
    "    \n",
    "#     #H advection\n",
    "#     H_SN = T_grad_NS.mul(-rho*z*cp*SN_wind/2000, axis = 0) #Advection of sensible heat by southerly wind [W/m^2]\n",
    "#     H_WE = T_grad_EW.mul(-rho*z*cp*SN_wind/2000, axis = 0) #Advection of sensible heat by westerly wind [W/m^2]\n",
    "#     H_ad = H_SN + H_WE #Total advection\n",
    "\n",
    "#     #LE advection\n",
    "#     LE_SN = H2O_grad_NS.mul(-z*L*SN_wind/2000, axis = 0)#Advection of latend heat by southerly wind [W/m^2]\n",
    "#     LE_WE = H2O_grad_EW.mul(-z*L*WE_wind/2000, axis = 0)#Advection of latent hear by westerly wind [W/m^2]\n",
    "#     LE_ad = (LE_SN + LE_WE)#*rho/rho #LE advection (the *rho/rho just makes it a df with the same tower and timestamp as indices)\n",
    "\n",
    "\n",
    "#     # hrz_ad = (H_ad + LE_ad)\n",
    "#     H_ad_tot = H_ad.sum(axis = 1)\n",
    "#     LE_ad_tot = LE_ad.sum(axis = 1)\n",
    "    \n",
    "#     return H_ad_tot, LE_ad_tot\n",
    "#     #Deal with water vapor later\n",
    "#     # md_w = e/(R*TA_K) #Molar density of water vapor [mol/m^3], used in SLE calc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d3383b-4c91-45a1-b194-13a33c77748c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# #Code for plotting T profiles\n",
    "# # plt.plot(df_mon.TA_1_1_1)\n",
    "\n",
    "# for tower in tc.index:\n",
    "#     if tower == 'PFA':\n",
    "#         pass\n",
    "    \n",
    "#     else:\n",
    "#         print(tower)\n",
    "#         towdat = tc.loc[tower] #Tower data\n",
    "#         filepath = towdat.org_path\n",
    "#         df = pd.read_csv(filepath)\n",
    "#         df = df.applymap(lambda x: np.nan if x == -9999 else x)\n",
    "\n",
    "#         #Add datetime index\n",
    "#         dt_ts = pd.to_datetime(df['TIMESTAMP_START'], format = '%Y%m%d%H%M') + dt.timedelta(minutes = 30) #half hour time stamp\n",
    "#         df.set_index(dt_ts, inplace = True)\n",
    "        \n",
    "#         #Add TA_1_2_1 and TA_1_3_1 for shorter towers\n",
    "#         # if towdat.z2 == 0:\n",
    "#         #     df['TA_1_2_1'] = np.nan\n",
    "#         if towdat.z3 == 0:\n",
    "#             # df['TA_1_3_1'] = np.nan\n",
    "#             pass\n",
    "        \n",
    "#         else:\n",
    "\n",
    "#             df_mon = df.groupby([df.index.month, df.index.time]).mean()\n",
    "\n",
    "#             fig, axs = plt.subplots(12, 4, figsize = (10, 30))\n",
    "#             for mon in range(6, 11):\n",
    "#                 # plt.plot(df_mon.TA_1_1_1[mon].values)\n",
    "#                 i=0\n",
    "#                 for hour in df_mon.TIMESTAMP_START[mon].index:\n",
    "#                     ax = axs[i//4, i%4]\n",
    "#                     i= i+1\n",
    "                    \n",
    "#                     TA_top = df_mon.TA_1_1_1[mon][hour] - df_mon.TA_1_2_1[mon][hour]\n",
    "#                     TA_bottom = df_mon.TA_1_3_1[mon][hour] - df_mon.TA_1_2_1[mon][hour]\n",
    "\n",
    "#                     # ax.plot([df_mon.TA_1_1_1[mon][hour], df_mon.TA_1_2_1[mon][hour],df_mon.TA_1_3_1[mon][hour]], [towdat.z1, towdat.z2, towdat.z3])\n",
    "#                     ax.plot([TA_top, 0, TA_bottom], [towdat.z1, towdat.z2, towdat.z3])\n",
    "#                     ax.set_yticks([towdat.z3, towdat.z2, towdat.z1])\n",
    "#                     ax.set_title(hour)\n",
    "#                     ax.set_xlim([-3, 3])\n",
    "\n",
    "#                 fig.suptitle(tower)\n",
    "#                 plt.tight_layout()\n",
    "#                 plt.savefig(str('./Outputs/diff_Profiles/' + tower + '_TA_diff_profiles'))\n",
    "# #Want to plot profile for each hour x = temperature, y = height\n",
    "# #Could make \n",
    "# # for timme in df_day.index:\n",
    "# #     profile = [\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060cf138-5708-4c1a-89fc-f74b338b9ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Taken from end of Interpfun\n",
    "This bit of code was to add back in towers with nan values that were remobed above. Not needed since \n",
    "it is still possible to interpolate to the points N, S, E, and W of those towers without data from the \n",
    "towers themselve. However, maybe a good idea to remove those points since interpolation might not be as \n",
    "acurate without having data from a nearby point...something to consider\n",
    "'''\n",
    "\n",
    "# nan_inds = np.where(nanmask == False)[0] - np.arange(0 ,len(np.where(nanmask == False)[0]))\n",
    "\n",
    "# dat_N.loc[dat_N.index ==i] = np.insert(dat_N_nn, nan_inds, np.nan)\n",
    "# dat_S.loc[dat_S.index ==i] = np.insert(dat_S_nn, nan_inds, np.nan)\n",
    "# dat_E.loc[dat_E.index ==i] = np.insert(dat_E_nn, nan_inds, np.nan)\n",
    "# dat_W.loc[dat_W.index ==i] = np.insert(dat_W_nn, nan_inds, np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce876e86-98eb-430f-ae95-3a83a145063c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_test = pd.read_csv('http://co2.aos.wisc.edu/data/CHEESEHEAD-incoming/Ameriflux/US-PFb_HH_201906010000_201911010000.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adcc7826-604a-4786-b1b8-34b692435b97",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
