{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c15c6ac-2dc8-4b13-aca0-002b7c622d37",
   "metadata": {},
   "source": [
    "# Note to self\n",
    "Next time start by:\n",
    "\n",
    "\n",
    "Then:\n",
    "- Check wind prof calcs\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a409ab8-58df-4449-a672-90ff22736e81",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa2039df-9306-44dc-8761-ceb173cd0b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#Specify whether to use CHEESEHEAD or synthtic data \n",
    "os.environ['config'] = 'CHEESEHEAD'\n",
    "# os.environ['config'] = 'synthetic'\n",
    "\n",
    "from setup import * #Import setup module\n",
    "from chad_funcs import *\n",
    "\n",
    "# import pdb #Add to setup if I'm going to use this often\n",
    "\n",
    "# #If using limited cases- full case list read in through setup module\n",
    "# cases = pd.read_csv('../Inputs/cases_limited.csv', index_col = 'case') #dataframe of tower coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3cdc6a4d-74c7-4251-9e9c-8eeaa50900eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # Reimport\n",
    "# import importlib\n",
    "# import chad_funcs\n",
    "# importlib.reload(chad_funcs)\n",
    "# from chad_funcs import*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5bf542e-3d05-4396-aa89-7e030db153f2",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a057b26-31f6-4f03-a659-6ffec3c13a69",
   "metadata": {},
   "source": [
    "## Hrz Advection Wrapping Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1cfec54-a482-4c2f-87f3-72f01eed1ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hrz advection calcs\n",
    "'''\n",
    "Function that caculates horizontal advection of H and LE\n",
    "\n",
    "Parameters:\n",
    "- hrz_grad_tow: horizontal gradients for given tower\n",
    "- WS: \n",
    "- step: step size for vertical profiles, defaule = 0.1 m\n",
    "\n",
    "'''\n",
    "\n",
    "def hrz_ad_calc(hrz_grad, WS, stab_meth, MO, dtindex, step = 0.1):\n",
    "    \n",
    "    H_adv = pd.DataFrame(index = dtindex, columns = towlist)\n",
    "    LE_adv = pd.DataFrame(index = dtindex, columns = towlist)\n",
    "    \n",
    "    for tow in towlist:\n",
    "        \n",
    "        #Used to have in if statement but I think this should work for all towers, delete if statement later if not needed\n",
    "        #if tc.loc[tow].z3 != 0: #All three-level towers \n",
    "        WS_prof = wind_prof(tow, stab_meth, WS[tow], MO[tow], dtindex, step, z_Umes = 'use_mes')        \n",
    "\n",
    "        #H advection\n",
    "        H_adv_step = prof_calcs(tow, hrz_grad['TA'], 'interp', dtindex, step).values*WS_prof.mul(-rho[tow]*cp*step, axis = 0) #Advection of sensible heat\n",
    "        #Units W/m^2 = K/m                   [m/s]     [kg/m^3][J/kg*K][m]\n",
    "\n",
    "        #LE advection\n",
    "        LE_adv_step = prof_calcs(tow, hrz_grad['H2O'], 'interp', dtindex, step).values*WS_prof.mul(-step*L) #Advection of latent heat\n",
    "        #Units: [W/m^2] =   [g/m^3/m]          [m/s]       [m]  [J/g]\n",
    "\n",
    "        #Note: The /1000 in both advection equations is because gradients are in per km and need to be in per m\n",
    "\n",
    "        # hrz_ad = (H_ad + LE_ad)\n",
    "        #Bottom value on all profiles is set to 0 so some profiles with all missing data still have 1 real value so min_count = 2\n",
    "        H_adv[tow] = H_adv_step.sum(axis = 1, min_count = 2)\n",
    "        LE_adv[tow] = LE_adv_step.sum(axis = 1, min_count = 2)\n",
    "                    \n",
    "    \n",
    "    return H_adv, LE_adv \n",
    "    \n",
    "    #Deal with water vapor later #fixthis what is this??\n",
    "    # md_w = e/(R*TA_K) #Molar density of water vapor [mol/m^3], used in SLE calc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e69d741d-e24e-4088-9eb4-8565082c976c",
   "metadata": {},
   "source": [
    "## Vertical Advection Calc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48ae3e96-e9f2-4df4-b84c-96e42bb66f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vert H and LE advection calcs\n",
    "def vert_ad_calc(tow, tracdat, w_tow, MO_tow, step = 0.1):\n",
    "\n",
    "    towdat = tc.loc[tow]\n",
    "    \n",
    "    TA_mean = prof_calcs(tow, tracdat['TA'], 'mes', dtindex, step).mean(axis = 1)\n",
    "    H2O_mean = prof_calcs(tow, tracdat['H2O'], 'mes', dtindex, step).mean(axis = 1)\n",
    "    \n",
    "    TA_diff = tracdat['TA'][towdat.top_lev, tow] - TA_mean\n",
    "    H2O_diff = tracdat['H2O'][towdat.top_lev, tow] - H2O_mean\n",
    "                   \n",
    "    H_vert = TA_diff*w_tow*rho[tow]*cp\n",
    "    LE_vert= H2O_diff*w_tow*L    \n",
    "    \n",
    "    return H_vert, LE_vert"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d39fb0bc-26e3-4403-8894-694023ebc1e9",
   "metadata": {},
   "source": [
    "## Profile Calcs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c33c796-cc92-4571-b6a8-b2ba4635dc5e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Wind Profile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d6d41a-584f-47f8-a29b-73e84bee263d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Profiles of tracer (or tracer gradients)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a358439-fb28-4dbf-9240-941b245275c9",
   "metadata": {},
   "source": [
    "# Setup this notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0def51af-2685-44ff-a982-fbb1788f122f",
   "metadata": {},
   "source": [
    "## Read in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b5726d5-368e-455d-827a-eedfa9432f9c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Full length\n",
    "startdate = dt.datetime(2019, 6, 20, 0)\n",
    "enddate = dt.datetime(2019, 10, 13, 23)\n",
    "# startdate = dt.datetime(2019, 7, 1)\n",
    "# enddate = dt.datetime(2019, 7, 2)\n",
    "\n",
    "dtindex = readdata('dtindex', startdate, enddate)\n",
    "\n",
    "#Read in data -potentially move into modules but that would make it challenging \n",
    "hrz_wind = readdata('hrz_wind', startdate, enddate) #Horizontal wind- includes WS_top, WD\n",
    "MO = readdata('MO', startdate, enddate)\n",
    "\n",
    "#Air density used in sensible head advection calc (hrz_ad_calc)\n",
    "TA_K = readdata('TA', startdate, enddate)[30] + CtoK #Temperature in Kelvin\n",
    "PA_top_Pa = readdata('PA_top', startdate, enddate)*1000 #kPa to Pa - probbably need to adjust for PFA\n",
    "rho = mm*PA_top_Pa/TA_K/R #Dry air density at each tower [kg/m^3] **should probably use virtual temperature here** #fixthis\n",
    "\n",
    "#Gap filling\n",
    "for tow in towlist:\n",
    "    rho[tow] = rho[tow].fillna(rho.mean(axis = 1)) \n",
    "\n",
    "# #Method dependent data (move into functions), could move into  #fixthis\n",
    "w_son = readdata('w_son', startdate, enddate)\n",
    "w_cont = readdata('w_cont', startdate, enddate)\n",
    "w_cont_lai = readdata('w_cont_lai', startdate, enddate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a8dc5a4-2749-47ed-839d-1f00991332d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tracdat = {'TA': readdata('TA', startdate, enddate),\n",
    "              'H2O': readdata('H2O', startdate, enddate)} "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1915fcd-9af9-4983-8774-ca9e2ade9624",
   "metadata": {},
   "source": [
    "# Run Calcs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62cad395-55e6-48fb-8693-c510595df5d5",
   "metadata": {},
   "source": [
    "## Horizontal Advection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9880d94e-aea9-452d-ac0d-c02250c3eb33",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A\n",
      "B\n",
      "C\n",
      "D\n",
      "E\n",
      "F\n",
      "G\n",
      "H\n",
      "I\n",
      "J\n",
      "K\n",
      "L\n"
     ]
    }
   ],
   "source": [
    "H_hrz = make_multi_df([cases.index, towlist], ['case', 'tow'], dtindex)\n",
    "LE_hrz = make_multi_df([cases.index, towlist], ['case', 'tow'], dtindex)\n",
    "\n",
    "for case in cases.index:\n",
    "    print(case)\n",
    "    grad_method = cases['grad_method'].loc[case]\n",
    "    interpdist = cases['interp_dist'].loc[case]\n",
    "    interpdir = cases['interp_dir'].loc[case]\n",
    "    stab_meth = cases['stability'].loc[case]\n",
    "    kernel = cases['interp_kernel'].loc[case]\n",
    "\n",
    "    if grad_method == 'gradavg':\n",
    "        filepath = intermed_filepath + 'hrz_gradients/'+ grad_method + '.pickle'\n",
    "        \n",
    "    elif grad_method == 'interp':\n",
    "        filepath = intermed_filepath + 'hrz_gradients/tracer' + grad_method + str(interpdist) + interpdir + kernel + '.pickle'\n",
    "    \n",
    "    # # Filepath for shortened time\n",
    "    filepath = intermed_filepath + 'hrz_gradients/tracer' + grad_method + str(interpdist) + str(interpdir) \\\n",
    "     + str(kernel) +str(stab_meth) + startdate.strftime(\"%m%d\")+ '-'+ enddate.strftime(\"%m%d\")+'.pickle'\n",
    "    \n",
    "    with open(filepath, 'rb') as handle:\n",
    "        hrz_grad = pickle.load(handle)\n",
    "        \n",
    "    H_hrz[case], LE_hrz[case] = hrz_ad_calc(hrz_grad, hrz_wind['WS_top'], stab_meth, MO, dtindex, step = 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80284949-137a-4299-9a5f-847b7c7955f8",
   "metadata": {},
   "source": [
    "### Export Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e2b333f-a340-4e6e-8e6e-ba310b825463",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = output_filepath + 'adv_final/H_hrz_all_lai.pickle'\n",
    "\n",
    "with open(filepath, 'wb') as handle:\n",
    "    pickle.dump(H_hrz, handle)\n",
    "\n",
    "    \n",
    "filepath = output_filepath + 'adv_final/LE_hrz_all_lai.pickle'\n",
    "\n",
    "\n",
    "with open(filepath, 'wb') as handle:\n",
    "    pickle.dump(LE_hrz, handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7dfbd8-772e-4b5b-927b-475259fba1e0",
   "metadata": {},
   "source": [
    "## Vertical Advection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de7f739a-7d8c-44bf-ad12-23105bb2543e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Calc vert adv for all 30 m towers (fiture out shorter towers later)\n",
    "vert_ad_all = make_multi_df([['H', 'LE'], towlist], ['var', 'tow'], dtindex)\n",
    "step = 0.1\n",
    "w_use = w_cont_lai \n",
    "stab_meth = None\n",
    "\n",
    "for tow in tc.index:\n",
    "    if tow == 'PFA' or tow == 'PFd' or tow == 'PFr':\n",
    "        pass\n",
    "    else:\n",
    "        vert_ad_all['H', tow], vert_ad_all['LE', tow] = vert_ad_calc(tow, tracdat, w_use[tow], MO[tow], step)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b75557ae-45b7-4123-88e9-b6944deb3655",
   "metadata": {},
   "source": [
    "### Export Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fc6269ab-f606-4c99-9710-77ed323dcd5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filepath = output_filepath + 'adv_final/vert_ad_cont_lai.pickle'\n",
    "\n",
    "\n",
    "# with open(filepath, 'wb') as handle:\n",
    "#     pickle.dump(vert_ad_all, handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ebe7a0d-6d66-4bd0-8ad4-23789d5041e2",
   "metadata": {},
   "source": [
    "# Testing/plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b4b31a-ad7d-4af1-b842-8a5d00feafda",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "# Archive/need to figure out what this stuff does"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "affc1b5a-bf9f-42af-a5fb-dee435269c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #color list\n",
    "# colorlist = [\"xkcd:ocean blue\", \"xkcd:terracotta\", \"xkcd:blue green\",\"xkcd:grape\",  \"xkcd:grey\",  \n",
    "#              \"xkcd:forrest green\",\"xkcd:magenta\", \"xkcd:grey blue\", \"xkcd:dark yellow\",\"xkcd:coral\",\n",
    "#               \"xkcd:sky blue\", \"xkcd:light orange\",\"xkcd:reddish brown\", \"xkcd:dark lavender\",  \"xkcd:light olive\",\n",
    "#              \"xkcd:puke yellow\", \"xkcd:light cyan\", \"xkcd:orchid\",  \"xkcd:periwinkle blue\"]\n",
    "# mpl.rcParams['axes.prop_cycle'] = mpl.cycler(color=colorlist) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d6d7e47e-f323-41db-8d48-ff7160a1f9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tow = 'PFm'\n",
    "# dir_range = np.arange(0, 370, 10)\n",
    "# w_grouped1 = w_cont[tow].groupby(pd.cut(hrz_wind['WD'][tow], dir_range)).mean()\n",
    "# w_grouped2= w_son[tow].groupby(pd.cut(hrz_wind['WD'][tow], dir_range)).mean()\n",
    "# plt.plot(dir_range[0:-1], w_grouped1)\n",
    "# plt.plot(dir_range[0:-1], w_grouped2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c1a5130d-eafb-4b3f-a3b4-d48c81a94aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tow = 'PFp'\n",
    "# dir_range = np.arange(0, 370, 10)\n",
    "# flux_grouped1 = H_hrz[2][tow].groupby(pd.cut(hrz_wind['WD'][tow], dir_range)).mean()\n",
    "# flux_grouped2= LE_hrz[2][tow].groupby(pd.cut(hrz_wind['WD'][tow], dir_range)).mean()\n",
    "# plt.plot(dir_range[0:-1], flux_grouped1)\n",
    "# plt.plot(dir_range[0:-1], flux_grouped2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f00df4ad-3c9a-4971-909f-392c77b52345",
   "metadata": {},
   "outputs": [],
   "source": [
    "# w_son[tow].groupby(hrz_wind['WD'][tow])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c317ec88-73d6-43e7-b0ec-690ecc4e050f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # dat_use = w_cont\n",
    "# dat_use = H_hrz[2]\n",
    "# for tow in towlist:\n",
    "#     plt.plot(dat_use[tow].groupby(dat_use.index.hour).mean(), label = tow);\n",
    "# plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fc03dfd7-27cc-415f-a1d6-f004bad52917",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(vert_ad_all_cont['H', 'PFg'].groupby(vert_ad_all_son.index.hour).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dae8d547-97fe-4883-a80d-c31ae9e035dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tow = 'PFg'\n",
    "# plt.hist(vert_ad_all_son['H', tow], bins = 50);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc060349-0f61-4481-bb1c-afee6c84d565",
   "metadata": {},
   "source": [
    "## Labeled code chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "871e86e2-9362-4b08-93d2-443dca757a6a",
   "metadata": {},
   "source": [
    "### Old wind profile method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bd70ca9f-2865-4cc7-ad3c-2bb842cb1151",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Can probably get rid of this later, maybe save and compare wind profiles with \\nstability correction to wind profiles from Ustar without using ratio to correct'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' Can probably get rid of this later, maybe save and compare wind profiles with \n",
    "stability correction to wind profiles from Ustar without using ratio to correct'''\n",
    "\n",
    "# #Formetly in Wind profile calc function, when using Ustar from data, now using ration approach which should give same result\n",
    "# WS_calc = WS_top_calc(tow)\n",
    "# WS_calc_rat = hrz_wind['WS_top'][tow]/WS_calc\n",
    "# u_of_h = hrz_wind['Ustar'][tow]/k*np.log((h_veg-d)/z_m)*WS_calc_rat #wind speed at top of canopy\n",
    "\n",
    "\n",
    "# #Function to calc wind speed at top of tower using ustar\n",
    "# def WS_top_calc(tow):\n",
    "#     k = 0.4 #von Karman constant\n",
    "    \n",
    "\n",
    "#     h_tow = tc.z1.loc[tow] #Tower height\n",
    "#     h_veg = tc.veg_h.loc[tow] #Vegetation height\n",
    "#     z0 = 0.1*h_veg #roughness length,might be good to look at plant data to better estimate\n",
    "#     d = tc.d.loc[tow] #Displacement height\n",
    "    \n",
    "#     WS_calc = (hrz_wind['Ustar'][tow]/k)*np.log((h_tow - d)/(z0))\n",
    "#     return WS_calc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c4e6749-4d9e-45ac-ae8b-911e3f83ff36",
   "metadata": {},
   "source": [
    "### Wind profile testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "340e6fa6-e913-4a78-b6cc-4d478dc2e730",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assessing wind profile calculations\n",
    "# WS_calc = pd.DataFrame(index = dtindex)\n",
    "# for tow in towlist:\n",
    "#     WS_calc[tow]= WS_top_calc('PFb', d_rat = 0.65)\n",
    "# WS_real = hrz_wind.loc['WS_top']\n",
    "# RMSE = (((WS_calc - WS_real)**2).mean()**(1/2))#.mean()\n",
    "\n",
    "# wind_rat_all = WS_calc/WS_real\n",
    "# wind_rat_di = wind_rat_all.groupby([wind_rat_all.index.hour, wind_rat_all.index.minute]).mean()\n",
    "# xvals = wind_rat_di.index.get_level_values(0).values + wind_rat_di.index.get_level_values(1).values/60\n",
    "# wind_rat_di.set_index(xvals, inplace = True)\n",
    "# wind_rat_di.plot(figsize = (15, 5))\n",
    "# plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "# plt.xlabel('hour')\n",
    "# plt.ylabel('WS_calc/WS_mes')\n",
    "\n",
    "# #Attempt to calculate d from WS and Ustar - didn't work well, got huge numbers\n",
    "# d_calc = pd.DataFrame(index = dtindex)\n",
    "\n",
    "# for tow in towlist:\n",
    "#     z = tc.z1.loc[tow]\n",
    "#     z0 = tc.veg_h.loc[tow]*0.1\n",
    "#     Ustar_pos = hrz_wind.loc['Ustar'][tow].where(hrz_wind.loc['Ustar'][tow]>0)\n",
    "#     d_calc[tow] = z - z0*np.exp(hrz_wind.loc['WS_top'][tow]*k/Ustar_pos)\n",
    "#     # d_calc[tow] = np.exp(hrz_wind.loc['WS_top'][tow]*k/Ustar_pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b9cbf3-9eb8-40ce-b950-01f680e0fdcd",
   "metadata": {},
   "source": [
    "### Save output data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "46d44771-2ecd-4e92-81ac-ab03655e976e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving output data\n",
    "# filepath = '../Outputs/Hrz_adv/vardirtest_LE_adv'\n",
    "\n",
    "# with open(filepath, 'wb') as handle:\n",
    "# pickle.dump(LE_ad, handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846dcd40-0efa-46d6-b37a-d2714ea2007f",
   "metadata": {},
   "source": [
    "### Seasonal transition dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e196ae34-7a87-495e-85c2-b5d92a2d6bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Approximate dates of transition between dry, wet and windy seasons\n",
    "\n",
    "# date1 = dt.datetime(2019, 7, 1)\n",
    "# date2 = dt.datetime(2019, 7, 12)\n",
    "# date3 = dt.datetime(2019, 8, 20)\n",
    "# date4 = dt.datetime(2019, 7, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ff5d9f-027c-43ce-b5df-240bbaca2c06",
   "metadata": {},
   "source": [
    "## Unblabled/unorganized code chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "56e82f4a-7f61-47b3-868b-6055cdf1a899",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Code to rename vert_wind columns - from var names to tow names\n",
    "# # Don't need because I resaved the pickel with new column names\n",
    "# tow_names =  dict(zip(tc.wind_var[1:], tc.index[1:])) #Dictionary to relate \n",
    "# vert_wind = vert_wind.rename(columns = tow_names)\n",
    "# vert_wind['PFA'] = np.nan #Add column for PFA since I don't have sonic data for it - maybe see if I can get that\n",
    "# vert_wind = vert_wind[towlist]\n",
    "# vert_wind.to_pickle('../Inputs/w_son.pickle') #<-here's how I renamed it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "89ab4bdb-a34d-428a-9482-284023fdf692",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filepath for shortened time saved data\n",
    "# filepath = '../intermed_data/hrz_gradients/vardirtest_'+ str(interpdist) + interpdir \\\n",
    "# + startdate.strftime(\"%m%d\")+ '-'+ enddate.strftime(\"%m%d\")+'.pickle'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c7cdc83b-efde-4600-9090-855a22032a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Function to read in universal data\n",
    "# #Reads in all data unless start and end date are specified\n",
    "# def read_unidata(startdate = dt.datetime(2019, 6, 1), enddate = dt.datetime(2019, 11, 1)):\n",
    "#     unidata_paths = {\n",
    "#         'TA':'../Inputs/TA_orig_all.pickle',\n",
    "#         'H2O':'../Inputs/H2O_orig_all.pickle',\n",
    "#         'hrz_wind': '../Inputs/wind_dat.pickle',\n",
    "#         'PA_top': '../Inputs/PA_top.pickle'}\n",
    "#     unidata = {} #Save all data in unidata in unidata \n",
    "#     for var in unidata_paths.keys():\n",
    "#         if var == 'PA_top':\n",
    "#             #No levels for PA, select start to end date\n",
    "#             unidata[var] = pd.read_pickle(unidata_paths[var]).loc[startdate:enddate] \n",
    "#         else:\n",
    "#             #Select all levels, start to end date, all tows\n",
    "#             unidata[var] = pd.read_pickle(unidata_paths[var]).loc[idx[:, startdate:enddate], :] \n",
    "            \n",
    "#     unidata['dtindex'] = unidata['TA'].loc[2].index #Datetime index for all datasets\n",
    "#     return unidata\n",
    "        \n",
    "#Function for creating multiindexed dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0bdeae7b-04c5-4b96-ac0b-bc5dd3334bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Calc hrz adv for all 30 m tows (fiture out shorter towers later)\n",
    "# H_vert_d = pd.DataFrame()\n",
    "# LE_vert_d = pd.DataFrame()\n",
    "\n",
    "# for tow in tc.index:\n",
    "#     if tc.loc[tow].z1 == 30:\n",
    "#         if tow == 'PFA':\n",
    "#             pass\n",
    "#         else:\n",
    "#             H_vert, LE_vert = vert_ad_d_calc(tow)\n",
    "#             H_vert_d[tow] = H_vert\n",
    "#             LE_vert_d[tow] = LE_vert\n",
    "        \n",
    "# vert_ad_d = pd.concat([H_vert_d, LE_vert_d], keys = ['H', 'LE'])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dc9ec0ae-df6b-4a1d-a469-df4c8993e0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for tow in tc.index:\n",
    "#     if tow in ['PFA', 'PFc', 'PFd', 'PFl', 'PFr', 'PFs']:\n",
    "#         pass\n",
    "#     else:\n",
    "#         for var in ['LE', 'H']:\n",
    "#             if var == 'LE':\n",
    "#                 max_bin = 2000\n",
    "#             else:\n",
    "#                 max_bin = 500\n",
    "#             # f1 = plt.figure()\n",
    "#             min_bin = -max_bin\n",
    "\n",
    "#             binwidth = max_bin//25\n",
    "\n",
    "#             plt.hist(vert_ad[tow].loc[var], bins=range(min_bin, max_bin + binwidth, binwidth), density = True);\n",
    "#             plt.hist(vert_ad_d[tow].loc[var], bins = range(min_bin, max_bin + binwidth, binwidth), alpha = 0.7, density = True);\n",
    "\n",
    "#             plt.xlabel(var + ' [$W/m^2$]')\n",
    "#             plt.ylabel('Frequency')\n",
    "\n",
    "#             plt.savefig('./Outputs/d_v_0_vert_ad/' + tow + '_' + var)\n",
    "#             plt.cla()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393889a5-fce5-4ca7-9bf3-16461138dcfa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "988f2068-4aa1-4896-be49-ecb484016bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tower = 'PFb'\n",
    "\n",
    "# #Calc vert T diff (only works for 30 m towers(only works for 30 m towers\n",
    "# TA_30 = TA.loc[30][tower]\n",
    "# TA_10 = TA.loc[10][tower]\n",
    "# TA_2 = TA.loc[2][tower]\n",
    "# TA_0 = TA_2 - (TA_10 - TA_2)*(2/8) #Surface temp\n",
    "# TA_diff = TA_0 - TA_30 \n",
    "\n",
    "# #Cut out upper and lower 10% of TA_diff\n",
    "# l_cutoff = np.nanpercentile(TA_diff, 10)\n",
    "# u_cutoff = np.nanpercentile(TA_diff, 90)\n",
    "\n",
    "# #TA_diff = TA_diff.where(TA_diff>l_cutoff)#.where(TA_diff<u_cutoff)\n",
    "# plt.hist(TA_diff, bins = 50)\n",
    "# plt.axvline(x = l_cutoff, color = 'r')\n",
    "# plt.axvline(x = u_cutoff, color = 'r')\n",
    "# plt.savefig('../Outputs/Poster_plots/PFh_TA_diff_hist.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e39e73-b653-40da-97ec-ecb6ad4d9dac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a054d7cf-64d2-4d28-885d-c0d09775cd3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(TA_diff.groupby(TA_diff.index.hour).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "476d0de0-4503-4156-b895-6c52b0721835",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tower = 'PFb'\n",
    "# H_ad_use = vert_ad.loc['H'][tower]\n",
    "\n",
    "# vert_H_l_cut = np.nanpercentile(H_ad_use, 5)\n",
    "# vert_H_u_cut = np.nanpercentile(H_ad_use, 95)\n",
    "\n",
    "# # vert_H_cut = H_ad_use.where(H_ad_use >vert_H_l_cut).where(H_ad_use <vert_H_u_cut)\n",
    "\n",
    "# print(vert_H_l_cut, vert_H_u_cut)\n",
    "\n",
    "# plt.hist(H_ad_use, bins = 50)\n",
    "# plt.axvline(x = vert_H_l_cut, color = 'r')\n",
    "# plt.axvline(x = vert_H_u_cut, color = 'r')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "26b07c47-97d2-44ab-877c-79b1f03bf730",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# plt.hist(vert_ad.loc['H']['PFb'], bins = 100, density = True);\n",
    "# plt.hist(vert_ad.loc['LE']['PFb'], bins = 100, density = True, alpha = 0.7);\n",
    "\n",
    "# print(vert_ad.loc['H']['PFg'].mean(), vert_ad.loc['LE']['PFg'].mean() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2f1ec59c-dd99-4111-9653-46c76831cd10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# time_index = np.arange(0, 24, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "100b4fad-4cb8-4052-93f5-21fc688434b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.hist(wind_tt.values.flatten(), bins = 50);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "91cfe974-265e-42a5-b1b4-77b803f47c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vert_H = vert_ad.loc['H'][startdate:enddate]\n",
    "# wind_tt = vert_wind[vert_H.columns]#vert wind for tall towers\n",
    "\n",
    "# plt.scatter(wind_tt, vert_H/wind_tt);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2d6cc27a-873f-4111-b55a-8e2ef6105501",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tower = 'PFm'\n",
    "# TA_2 = TA.loc[2][startdate:enddate][vert_H.columns]\n",
    "# TA_30 = TA.loc[30][startdate:enddate][vert_H.columns]\n",
    "# TA_0 = TA_2 - (TA_10 - TA_2)*(2/8)\n",
    "# TA_diff = TA_30-TA_0\n",
    "\n",
    "# TA_use = TA_diff[tower]\n",
    "\n",
    "# vert_LE = vert_ad.loc['LE'][startdate:enddate]\n",
    "# wind_tt = vert_wind[vert_H.columns][tower]#vert wind for tall towers\n",
    "\n",
    "# bad_indices = np.isnan(wind_tt) | np.isnan(TA_use)\n",
    "# good_indices = ~bad_indices\n",
    "# good_wind = wind_tt[good_indices]\n",
    "# good_TA = TA_use[good_indices]\n",
    "\n",
    "# plt.hist2d(good_wind, good_TA, bins = 50);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "245cac23-82c6-4f88-bfab-aded5ca8b1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.scatter(hrz_ad.loc['H'][vert_H.columns], vert_ad.loc['H'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "67694492-1eeb-46ee-9399-75ca6e511253",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Note: removed changing line color by date - no decernable seasonal pattern\n",
    "\n",
    "# cmap = plt.get_cmap('viridis').reversed()\n",
    "# norm = plt.Normalize(0, len(vert_ad.loc['H'].index.date))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d587cbb9-7357-4674-bd72-f8933b664f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cutoff = 50\n",
    "# df_precut = vert_ad.loc['H']['PFe']\n",
    "\n",
    "# df = df_precut.where(df_precut<cutoff).where(df_precut>-cutoff)\n",
    "# for day in vert_ad.loc['H'].index.date:\n",
    "\n",
    "#     plt.plot(time_index, df[np.in1d(df.index.date, [day])], linewidth = 0.1, color = 'lightslategray')\n",
    "#     plt.xlabel('Hour')\n",
    "#     plt.ylabel('Vertical Sensible Heat Advective Flux $W/m^2$')\n",
    "    \n",
    "# plt.ylim(-cutoff, cutoff)\n",
    "\n",
    "# # plt.ylim(-250, 250)\n",
    "# plt.plot(time_index, df.groupby(df.index.time).mean(), 'k', linewidth = 3)\n",
    "\n",
    "# plt.savefig('../Outputs/Poster_plots/H_vert_PFe_daily_cut.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "695b7113-7e58-45c6-9a44-a603c55dd1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cutoff = 50\n",
    "# df_precut = vert_ad.loc['LE']['PFe']\n",
    "\n",
    "\n",
    "# df = df_precut.where(df_precut<cutoff).where(df_precut>-cutoff)\n",
    "# for day in vert_ad.loc['LE'].index.date:\n",
    "    \n",
    "#     plt.plot(time_index, df[np.in1d(df.index.date, [day])], linewidth = 0.2, color = 'lightslategray')\n",
    "#     plt.xlabel('Hour')\n",
    "#     plt.ylabel('Vertical Latent Heat Advective Flux $W/m^2$')\n",
    "    \n",
    "# # plt.ylim(-500, 500)\n",
    "# plt.ylim(-cutoff, cutoff)\n",
    "# plt.plot(time_index, df.groupby(df.index.time).mean(), 'k', linewidth = 3)\n",
    "\n",
    "# plt.savefig('../Outputs/Poster_plots/LE_vert_PFe_daily_cut.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "afefb3e3-531e-427e-a32b-b1907a1fb7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = hrz_ad.loc['H']['PFe']\n",
    "\n",
    "# for day in vert_ad.loc['H'].index.date:\n",
    "    \n",
    "#     linecolor = cmap(norm(i))\n",
    "#     plt.plot(time_index, df[np.in1d(df.index.date, [day])], linewidth = 0.1, color = 'lightslategray')\n",
    "#     plt.xlabel('Hour')\n",
    "#     plt.ylabel('Horizontal Sensible Heat Advective Flux $W/m^2$')\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "# plt.ylim(-8, 8)\n",
    "# plt.plot(time_index, df.groupby(df.index.time).mean(), 'k', linewidth = 3)\n",
    "\n",
    "# plt.savefig('../Outputs/Poster_plots/H_hrz_PFe_daily_all.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7a67a523-bf91-4b50-afd9-7a5632f67742",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = hrz_ad.loc['LE']['PFe']\n",
    "\n",
    "# for day in vert_ad.loc['LE'].index.date:\n",
    "    \n",
    "#     linecolor = cmap(norm(i))\n",
    "#     plt.plot(time_index, df[np.in1d(df.index.date, [day])], linewidth = 0.1, color = 'lightslategray')\n",
    "#     plt.xlabel('Hour')\n",
    "#     plt.ylabel('Horizontal Latent Heat Advective Flux $W/m^2$')\n",
    "    \n",
    "    \n",
    "    \n",
    "# plt.ylim(-15, 15)\n",
    "# plt.plot(time_index, df.groupby(df.index.time).mean(), 'k', linewidth = 3)\n",
    "\n",
    "# plt.savefig('../Outputs/Poster_plots/LE_hrz_PFe_daily_all.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "566bff7d-9568-46f2-b500-cfc48b309630",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LE_vert_day = vert_ad.loc['LE'].groupby(vert_ad.loc['LE'].index.hour).mean()\n",
    "# plt.plot(LE_vert_day);\n",
    "# plt.ylabel('Calculated Vertical Advection of Latent Heat [$W/m^2$]')\n",
    "# plt.xlabel('Hour')\n",
    "# plt.savefig('../Outputs/Poster_plots/LE_vert_ad_all.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4702859a-ccdd-452a-ab6d-b0aac7efef36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LE_vert_day = vert_ad.loc['H'].groupby(vert_ad.loc['H'].index.hour).mean()\n",
    "# plt.plot(LE_vert_day);\n",
    "# plt.ylabel('Calculated Vertical Advection of Sensible Heat [$W/m^2$]')\n",
    "# plt.xlabel('Hour')\n",
    "# plt.savefig('../Outputs/Poster_plots/H_vert_ad_all.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bfef723e-99e8-4aae-96d9-980a21abc975",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LE_vert_day = hrz_ad.loc['H'].groupby(hrz_ad.loc['H'].index.hour).mean()\n",
    "# plt.plot(LE_vert_day);\n",
    "# plt.ylabel('Calculated Horizontal Advection of Sensible Heat [$W/m^2$]')\n",
    "# plt.xlabel('Hour')\n",
    "# plt.savefig('../Outputs/Poster_plots/H_hrz_ad_all.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "42a2421c-bf75-4f6a-ad57-cbb60d385000",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LE_vert_day = hrz_ad.loc['LE'].groupby(hrz_ad.loc['LE'].index.hour).mean()\n",
    "# plt.plot(LE_vert_day);\n",
    "# plt.ylabel('Calculated Horizontal Advection of Latent Heat [$W/m^2$]')\n",
    "# plt.xlabel('Hour')\n",
    "# plt.savefig('../Outputs/Poster_plots/LE_hrz_ad_all.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5578ebe2-edb8-4b48-a9b2-141f53fc1935",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def day_cyc(dat):\n",
    "#     dat_day = dat.groupby(dat.index.time).mean()\n",
    "#     return dat_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a58d4a24-b980-4a90-90be-d78f3fce7a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tower = 'PFi'\n",
    "\n",
    "# filepath = tc.org_path.loc[tower]\n",
    "# df = pd.read_csv(filepath)\n",
    "\n",
    "# df = df.applymap(lambda x: np.nan if x == -9999 else x)\n",
    "\n",
    "# dt_ts = pd.to_datetime(df['TIMESTAMP_START'], format = '%Y%m%d%H%M') \n",
    "# df.set_index(dt_ts, inplace = True)\n",
    "\n",
    "\n",
    "# startdate = dt.datetime(2019, 6, 20, 1)\n",
    "# enddate = dt.datetime(2019, 10, 14, 23)\n",
    "# df = df[startdate:enddate]\n",
    "\n",
    "# NETRAD = df.NETRAD_1_1_1\n",
    "# LE_turb = df.LE_1_1_1\n",
    "# H_turb = df.H_1_1_1\n",
    "# G = df. G_1_1_1\n",
    "\n",
    "# LE_ad_hrz = hrz_ad.loc['LE'][tower]\n",
    "# H_ad_hrz = hrz_ad.loc['H'][tower]\n",
    "\n",
    "# LE_ad_vert = vert_ad.loc['LE'][tower]\n",
    "# H_ad_vert = vert_ad.loc['H'][tower]\n",
    "\n",
    "# E_bal = NETRAD - LE_turb - H_turb - G - LE_ad_hrz - H_ad_hrz - LE_ad_vert - H_ad_vert\n",
    "\n",
    "# E_out = LE_turb + H_turb + G + LE_ad_hrz + H_ad_hrz + LE_ad_vert + H_ad_vert\n",
    "\n",
    "# E_out_no_ad = LE_turb + H_turb + G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c8dfb6e2-a157-42e1-9076-f09f865ff37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(np.cumsum(day_cyc(NETRAD)))\n",
    "# # plt.plot(day_cyc(LE_turb))\n",
    "# # plt.plot(day_cyc(H_turb))\n",
    "# # plt.plot(day_cyc(G))\n",
    "# # plt.plot(day_cyc(LE_ad_hrz))\n",
    "# # plt.plot(day_cyc(H_ad_hrz))\n",
    "# # plt.plot(day_cyc(LE_ad_vert))\n",
    "# # plt.plot(day_cyc(H_ad_vert))\n",
    "\n",
    "# plt.plot(np.cumsum(day_cyc(E_out_no_ad)))\n",
    "# plt.plot(np.cumsum(day_cyc(E_out)))\n",
    "\n",
    "# # plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9a80d233-b7c4-43c1-a4dd-b89ae1601b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # time_ind = hrz_ad.loc['H'].groupby(hrz_ad.loc['H'].index.time).mean().index\n",
    "# time_ind = np.arange(0, 24, 0.5)\n",
    "\n",
    "# fig, axs = plt.subplots(3,4, figsize = [13, 8], sharex=True, sharey=True)\n",
    "# for i in range(0,3):\n",
    "#     for j in range(0,4):\n",
    "#         tower = hrz_ad.columns[i*4+j +1]\n",
    "        \n",
    "        \n",
    "#         filepath = tc.org_path.loc[tower]\n",
    "#         df = pd.read_csv(filepath)\n",
    "\n",
    "#         df = df.applymap(lambda x: np.nan if x == -9999 else x)\n",
    "\n",
    "#         dt_ts = pd.to_datetime(df['TIMESTAMP_START'], format = '%Y%m%d%H%M') \n",
    "#         df.set_index(dt_ts, inplace = True)\n",
    "\n",
    "\n",
    "#         startdate = dt.datetime(2019, 6, 20, 1)\n",
    "#         enddate = dt.datetime(2019, 10, 14, 23)\n",
    "#         df = df[startdate:enddate]\n",
    "\n",
    "#         NETRAD = df.NETRAD_1_1_1\n",
    "#         LE_turb = df.LE_1_1_1\n",
    "#         H_turb = df.H_1_1_1\n",
    "#         G = df. G_1_1_1\n",
    "\n",
    "#         LE_ad_hrz = hrz_ad.loc['LE'][tower]\n",
    "#         H_ad_hrz = hrz_ad.loc['H'][tower]\n",
    "\n",
    "#         LE_ad_vert = vert_ad.loc['LE'][tower]\n",
    "#         H_ad_vert = vert_ad.loc['H'][tower]\n",
    "\n",
    "#         E_bal = NETRAD - LE_turb - H_turb - G - LE_ad_hrz - H_ad_hrz - LE_ad_vert - H_ad_vert\n",
    "\n",
    "#         E_out = LE_turb + H_turb + G + LE_ad_hrz + H_ad_hrz + LE_ad_vert + H_ad_vert\n",
    "\n",
    "#         E_out_no_ad = LE_turb + H_turb + G\n",
    "        \n",
    "#         E_out_hrz_only = LE_turb + H_turb + G + LE_ad_hrz + H_ad_hrz\n",
    "        \n",
    "        \n",
    "        \n",
    "#         # axs[i, j].plot((np.cumsum(day_cyc(NETRAD).values)))\n",
    "#         # axs[i, j].plot((np.cumsum(day_cyc(E_out).values)))\n",
    "#         # axs[i, j].plot((np.cumsum(day_cyc(E_out_no_ad).values)))\n",
    "#         # axs[i, j].plot((np.cumsum(day_cyc(E_out_hrz_only).values)))\n",
    "        \n",
    "#         a = axs[i, j].plot(time_ind, day_cyc(NETRAD).values, color = 'coral')\n",
    "#         # b = axs[i, j].plot(time_ind, day_cyc(E_out).values, color = 'olivedrab')\n",
    "#         c = axs[i, j].plot(time_ind, day_cyc(E_out_no_ad).values, color = 'cornflowerblue')\n",
    "        \n",
    "        \n",
    "#         # axs[i, j].plot(day_cyc(E_out_hrz_only).values)\n",
    "        \n",
    "# fig.supxlabel('Hour')\n",
    "# fig.supylabel('Energy Flux [$W/m^2$]')\n",
    "# fig.legend([a, b, c], labels = ['Net radiation', 'Turbulent, ground and advective heat fluxes', 'Turbulent and ground heat flux only'], loc=\"upper right\")\n",
    "\n",
    "# fig.savefig('../Outputs/Poster_plots/diurnal_ebal_alltow.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5542c836-ec22-4bfa-b96e-55319ccf6641",
   "metadata": {},
   "outputs": [],
   "source": [
    "# err_df = pd.DataFrame(columns = ['gap_change_med', 'gap_change_mean', 'gap_change_med_cut', 'gap_change_mean_cut'])#,\n",
    "#                                 # 'gap_change_hrz_ad_only_med', 'gap_change_hrz_ad_only_med'])\n",
    "# for tower in vert_ad.columns:\n",
    "#     filepath = tc.org_path.loc[tower]\n",
    "#     df = pd.read_csv(filepath)\n",
    "\n",
    "#     df = df.applymap(lambda x: np.nan if x == -9999 else x)\n",
    "\n",
    "#     dt_ts = pd.to_datetime(df['TIMESTAMP_START'], format = '%Y%m%d%H%M') \n",
    "#     df.set_index(dt_ts, inplace = True)\n",
    "\n",
    "\n",
    "#     startdate = dt.datetime(2019, 6, 20, 1)\n",
    "#     enddate = dt.datetime(2019, 10, 14, 23)\n",
    "#     df = df[startdate:enddate]\n",
    "\n",
    "#     NETRAD = df.NETRAD_1_1_1\n",
    "#     LE_turb = df.LE_1_1_1\n",
    "#     H_turb = df.H_1_1_1\n",
    "#     G = df. G_1_1_1\n",
    "\n",
    "#     LE_ad_hrz = hrz_ad.loc['LE'][tower]\n",
    "#     H_ad_hrz = hrz_ad.loc['H'][tower]\n",
    "\n",
    "#     LE_ad_vert = vert_ad.loc['LE'][tower]\n",
    "#     H_ad_vert = vert_ad.loc['H'][tower]\n",
    "\n",
    "#     LE_ad_vert_cut = LE_ad_vert.where(LE_ad_vert>np.nanpercentile(LE_ad_vert, 10)).where(LE_ad_vert<np.nanpercentile(LE_ad_vert, 90))\n",
    "#     H_ad_vert_cut = H_ad_vert.where(H_ad_vert>np.nanpercentile(H_ad_vert, 10)).where(H_ad_vert<np.nanpercentile(H_ad_vert, 90))\n",
    "\n",
    "#     E_bal_org = NETRAD - LE_turb - H_turb - G\n",
    "\n",
    "#     E_bal_new = NETRAD - LE_turb - H_turb - G - LE_ad_hrz - H_ad_hrz - LE_ad_vert - H_ad_vert\n",
    "\n",
    "#     E_bal_new_cut = NETRAD - LE_turb - H_turb - G - LE_ad_hrz - H_ad_hrz - LE_ad_vert_cut - H_ad_vert_cut\n",
    "    \n",
    "#     E_bal_hrz = NETRAD - LE_turb - H_turb - G - LE_ad_hrz - H_ad_hrz\n",
    "\n",
    "#     # E_out = LE_turb + H_turb + G + LE_ad_hrz + H_ad_hrz + LE_ad_vert + H_ad_vert\n",
    "\n",
    "#     # E_out_no_ad = LE_turb + H_turb + G\n",
    "\n",
    "\n",
    "#     err_org = E_bal_org/NETRAD\n",
    "#     err_new = E_bal_new/NETRAD\n",
    "#     err_new_cut = E_bal_new_cut/NETRAD\n",
    "#     err_hrz_ad_only = E_bal_hrz/NETRAD\n",
    "\n",
    "#     # plt.hist(err_new, bins = 50, density = True);\n",
    "#     # plt.hist(err_org, bins = 50, alpha = .5, density = True);\n",
    "\n",
    "#     err_change = np.abs(err_org) - np.abs(err_new)\n",
    "#     err_change_cut = np.abs(err_org) - np.abs(err_new_cut)\n",
    "#     err_change_hrz_only = np.abs(err_org) - np.abs(err_hrz_ad_only)\n",
    "#     # plt.hist(err_change, bins = 100)\n",
    "#     err_df.loc[tower] = [err_change.median(), err_change.mean(), err_change_cut.median(), err_change_cut.mean()]#,\n",
    "#                         # err_change_hrz_only.median(), err_change_hrz_only.mean()]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "907dba16-6104-4910-9261-b68843d8d06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example T profile plot\n",
    "\n",
    "# tower = 'PFn'\n",
    "# TA_2 = TA.loc[2][tower].mean()\n",
    "# TA_10 = TA.loc[10][tower].mean()\n",
    "# TA_30 = TA.loc[30][tower].mean()\n",
    "# TA_0 = TA_2 - (TA_10 - TA_2)*(2/8)\n",
    "\n",
    "# plt.figure(figsize = (8,12))\n",
    "\n",
    "# plt.plot(TA_2, 2, marker='o', color = 'k')\n",
    "# plt.plot(TA_10, 10, marker='o',color = 'k')\n",
    "# plt.plot(TA_30, 30, marker='o', color = 'k')\n",
    "\n",
    "# plt.plot([TA_0, TA_10], [0, 10], linestyle = '--', color = 'k')\n",
    "# plt.plot([TA_10, TA_30], [10, 30], linestyle = '--', color = 'k')\n",
    "\n",
    "# plt.xlabel('Air temperature (degree C)')\n",
    "# plt.ylabel('Hight (m)')\n",
    "\n",
    "# plt.savefig('./Outputs/Poster_plots/PFn_TA_prof.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c92b9874-43f7-4f25-bedb-ec9c54973570",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Advection time series\n",
    "\n",
    "# tower = 'PFb'\n",
    "# # plt.plot(vert_ad.loc['H'][tower])\n",
    "# fig, axs = plt.subplots(4)\n",
    "# axs[0].plot(hrz_ad.loc['H'][tower])\n",
    "# axs[1].plot(hrz_ad.loc['LE'][tower])\n",
    "# axs[2].plot(vert_ad.loc['H'][tower])\n",
    "# axs[3].plot(vert_ad.loc['LE'][tower])\n",
    "# fig.tight_layout()\n",
    "# plt.savefig('./Outputs/Poster_plots/PFb_ad_all.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3d55b3a5-06d1-45c8-b948-601d95752f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# H_day = hrz_ad.loc['H'].groupby(hrz_ad.loc['H'].index.hour).mean()\n",
    "# plt.plot(H_day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4b3e92e3-556c-49ff-8a3b-95d8bbe2ff12",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Old version - for NSEW gradients\n",
    "\n",
    "# #Hrz advection calcs\n",
    "# #Function that caculates horizontal advection of H and LE\n",
    "# #Parameters:\n",
    "# #list parameters here\n",
    "\n",
    "# def hrz_ad_calc(tower, step = 0.1):\n",
    "\n",
    "#     WS_prof, T_grad_NS, T_grad_EW, H2O_grad_NS, H2O_grad_EW = prof_calcs(tower, step)\n",
    "    \n",
    "#     TA_K = TA.loc[30][tower] + CtoK\n",
    "    \n",
    "#     PA_Pa = PA_top[tower]*1000 #kPa to Pa **this is at top of tower(~400m), need PA val for 30m and below**\n",
    "#     rho = mm*PA_Pa/TA_K/R #Dry air density at each tower [kg/m^3] **should probably use virtual temperature here** \n",
    "#     z = step #np.asarray(tc.loc[tower].z1) #Height of each tower\n",
    "\n",
    "#     SN_wind = WS_prof.mul(np.sin(hrz_wind.loc['WD'][tower]*np.pi/180), axis = 0)\n",
    "#     WE_wind = WS_prof.mul(np.cos(hrz_wind.loc['WD'][tower]*np.pi/180), axis = 0)\n",
    "    \n",
    "#     #H advection\n",
    "#     H_SN = T_grad_NS*SN_wind.mul(-rho*z*cp/2000, axis = 0) #Advection of sensible heat by southerly wind [W/m^2]\n",
    "#     H_WE = T_grad_EW*WE_wind.mul(-rho*z*cp/2000, axis = 0) #Advection of sensible heat by westerly wind [W/m^2]\n",
    "#     H_ad = H_SN + H_WE #Total advection\n",
    "\n",
    "#     #LE advection\n",
    "#     LE_SN = H2O_grad_NS*SN_wind.mul(-z*L/2000) #Advection of latend heat by southerly wind [W/m^2]\n",
    "#     LE_WE = H2O_grad_EW*WE_wind.mul(-z*L/2000 )#Advection of latent hear by westerly wind [W/m^2]\n",
    "#     LE_ad = (LE_SN + LE_WE)#*rho/rho #LE advection (the *rho/rho just makes it a df with the same tower and timestamp as indices)\n",
    "\n",
    "\n",
    "#     # hrz_ad = (H_ad + LE_ad)\n",
    "#     H_ad_tot = H_ad.sum(axis = 1)\n",
    "#     LE_ad_tot = LE_ad.sum(axis = 1)\n",
    "    \n",
    "#     return H_ad_tot, LE_ad_tot\n",
    "#     #Deal with water vapor later\n",
    "#     # md_w = e/(R*TA_K) #Molar density of water vapor [mol/m^3], used in SLE calc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9904486b-a2c0-48ca-a3c5-35279060cda4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
