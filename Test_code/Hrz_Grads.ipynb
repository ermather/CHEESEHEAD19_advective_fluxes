{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "346abbb4-0802-4186-a37d-8894b33cf8e4",
   "metadata": {},
   "source": [
    "# Notes to self:\n",
    "Next time start by: \n",
    "\n",
    "Other things: \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f13d546a-f60e-4b98-84cd-21f004ae3e6c",
   "metadata": {},
   "source": [
    "# General Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c040f18-1578-4bc2-87d7-a096f0709f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#Specify whether to use CHEESEHEAD or synthtic data \n",
    "os.environ['config'] = 'CHEESEHEAD'\n",
    "# os.environ['config'] = 'synthetic'\n",
    "\n",
    "from setup import * #Import setup module\n",
    "\n",
    "from chad_funcs import *\n",
    "\n",
    "\n",
    "# #If using limited cases- full case list read in through setup module\n",
    "# cases = pd.read_csv('../Inputs/cases_limited.csv', index_col = 'case') #dataframe of tower coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1bf3d29-0d1a-4c88-837d-5d993d9b0448",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Reimport\n",
    "# import importlib\n",
    "# import setup\n",
    "# importlib.reload(setup)\n",
    "# from setup import*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc24eca-ad9d-48df-892d-8b65641831aa",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4377a6d2-c07c-4e38-b51a-64bf962ea2e9",
   "metadata": {},
   "source": [
    "## Nan Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09a5b6dd-3936-4203-b83c-3eb728f4353b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nancounts(data, varlist, levlist):\n",
    "    nancount =make_multi_df([varlist, levlist], ['var', 'lev'], dtindex) #Integer\n",
    "    nanmask = make_multi_df([varlist, levlist, towlist], ['var', 'lev', 'tow'], dtindex)#Boolean\n",
    "\n",
    "    for var in varlist: #Loop through both variable\n",
    "        for lev in levlist: #Loop through all three levels\n",
    "            nanmask[var, lev] = data[var][lev].notnull();\n",
    "            nancount[var, lev] = 18 - data[var][lev].count(axis=1)\n",
    "            \n",
    "    return nanmask, nancount"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b6926b-12e1-4a8a-93f5-538175d227cb",
   "metadata": {},
   "source": [
    "## Corrdinates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be1db574-6694-4391-b461-9fb4cdf3b75d",
   "metadata": {},
   "source": [
    "### NSEW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e600e846-9bb6-4c63-a828-06c5de5de4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to calculate coordinates at different dirs NSEW from each tower\n",
    "def NSEWcoords(dist, tc = tc): \n",
    "    tc_int = tc.copy() #Make copy of tc to put interpolation coords in\n",
    "    coords_dist = {} #Dictionary of NSEW coords at the specified distance\n",
    "    \n",
    "    #N, S, E, W coords (in km)\n",
    "    tc_int['y_N'] = tc_int['y'] + dist\n",
    "    tc_int['y_S'] = tc_int['y'] - dist\n",
    "    tc_int['x_E'] = tc_int['x'] + dist\n",
    "    tc_int['x_W'] = tc_int['x'] - dist\n",
    "\n",
    "    #Dictionary holding 2D array of coords for each tower in each direction \n",
    "    #Dims are tower, time, and direction (x/y)\n",
    "    coords_dist['N'] = np.stack((tc_int.x.values, tc_int.y_N.values)).T\n",
    "    coords_dist['S'] = np.stack((tc_int.x.values, tc_int.y_S.values)).T\n",
    "    coords_dist['E'] = np.stack((tc_int.x_E.values, tc_int.y.values)).T\n",
    "    coords_dist['W'] = np.stack((tc_int.x_W.values, tc_int.y.values)).T\n",
    "    \n",
    "    return coords_dist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5adcf979-60c6-4c58-924b-6f9a4990c305",
   "metadata": {},
   "source": [
    "### Up/down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5146414c-a34e-40ab-8bbb-5f34fd41ee18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def updowncoords(dist, WD, tc = tc):\n",
    "    \n",
    "    coords_dist = pd.DataFrame(index = dtindex, columns = towu2dirdim_cols)\n",
    "    WD = WD.astype(float)\n",
    "    #Locations dist km up and down wind from \n",
    "    coords_dist.loc[:, (slice(None), 'up', 'x')] = tc.x.values + dist*np.sin(WD*np.pi/180).values\n",
    "    coords_dist.loc[:, (slice(None), 'up', 'y')] = tc.y.values + dist*np.cos(WD*np.pi/180).values\n",
    "    coords_dist.loc[:, (slice(None), 'down', 'x')] = tc.x.values - dist*np.sin(WD*np.pi/180).values\n",
    "    coords_dist.loc[:, (slice(None), 'down', 'y')] = tc.y.values - dist*np.cos(WD*np.pi/180).values\n",
    "    \n",
    "    #Create dictionary \n",
    "    \n",
    "    return coords_dist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d509082-59d5-4ceb-b082-2ee2c4c694ca",
   "metadata": {},
   "source": [
    "### Geometry - convert NSEW to updown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "33b050c5-3464-4f39-8712-33e565936317",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_NSEW_to_updown(hrz_wind, grad_NSEW):\n",
    "    WD_rad = hrz_wind['WD']*np.pi/180 #Convert to radians\n",
    "    NS_grad = grad_NSEW.xs(\"NS\", level=\"direct\", axis=1, drop_level=True) #grad_NSEW.loc[:, (slice(None), 'NS')]\n",
    "    EW_grad = grad_NSEW.xs(\"EW\", level=\"direct\", axis=1, drop_level=True)\n",
    "    #Note this is the same as grad_NSEW.loc[:, (slice(None), 'EW')].droplevel(leve = 'direct', axis = 1)\n",
    "    grad_updown = NS_grad*np.cos(WD_rad.astype(float)) + EW_grad*np.sin(WD_rad.astype(float))\n",
    "    return grad_updown"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79fb0fde-b2ae-48ca-bb48-1efacc3b65c4",
   "metadata": {},
   "source": [
    "## Interpolation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1393e01-fb1e-4ae1-8557-bd09a7737392",
   "metadata": {},
   "source": [
    "### NSEW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8af9270c-8026-4e52-a44e-5124b114b70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interp_NSEW(data, coords_dist, dtindex, nancount_varlev, nanmask_varlev, kernel = 'thin_plate_spline'):\n",
    "    \n",
    "    #Create interp_dat dataframe with nested columns (tower>direction)\n",
    "    interped_dat = make_multi_df([towlist, NSEWdirlist], [\"tower\", \"direct\"], index = dtindex)\n",
    "\n",
    "    if kernel == 'quintic':\n",
    "        nancount_cutoff = 13\n",
    "    else:\n",
    "        nancount_cutoff = 16\n",
    "    \n",
    "    #Loop through timestep and interpolate\n",
    "    for i in dtindex:\n",
    "        dat_use = data.loc[data.index == i].values[0, :] #For each loop interpolate with just one row of data\n",
    "\n",
    "        dat_nn = dat_use[nanmask_varlev.loc[i]] #dat_use without nan values #fisthis - get rid of varlev\n",
    "        ar_nn = ar[nanmask_varlev.loc[i]] #coordinates of towers that have finite values\n",
    "        \n",
    "        if nancount_varlev.loc[i] >= nancount_cutoff:\n",
    "            pass\n",
    "            \n",
    "        else:\n",
    "            #Run interpolator\n",
    "            interpfunction = RBFInterpolator(ar_nn, dat_nn, kernel = kernel, epsilon = 1)\n",
    "\n",
    "            #Apply interpolation function to coords of points in each direction\n",
    "            for direct in NSEWdirlist:\n",
    "                interped_dat.loc[i, idx[:, direct]] = interpfunction(coords_dist[direct])\n",
    "                \n",
    "     \n",
    "            \n",
    "    return interped_dat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb93d2be-c18b-4813-89be-8116b8f96c58",
   "metadata": {},
   "source": [
    "### Up/down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c19a6d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interp_updown(data, coords_dist, dtindex, nancount_varlev, nanmask_varlev, kernel = 'thin_plate_spline'):\n",
    "\n",
    "    \n",
    "    #Create interp_dat dataframe with nested columns (tower>direction)\n",
    "    interped_dat = make_multi_df([towlist, u2_dirlist], [\"tower\", \"direct\"], index = dtindex)\n",
    "    \n",
    "    if kernel == 'quintic':\n",
    "        nancount_cutoff = 13\n",
    "    else:\n",
    "        nancount_cutoff = 16\n",
    "    \n",
    "    #Loop through timestep and interpolate\n",
    "    for i in dtindex:\n",
    "        dat_use = data.loc[data.index == i].values[0, :] #For each loop interpolate with just one row of data\n",
    "        \n",
    "        dat_nn = dat_use[nanmask_varlev.loc[i]] #dat_use without nan values\n",
    "        ar_nn = ar[nanmask_varlev.loc[i]] #coordinates of towers that have finite values\n",
    "        \n",
    "        if nancount_varlev.loc[i] >= nancount_cutoff:\n",
    "            pass\n",
    "            \n",
    "        else:\n",
    "\n",
    "            #Run interpolator\n",
    "            interpfunction = RBFInterpolator(ar_nn, dat_nn, kernel = kernel, epsilon = 1)\n",
    "\n",
    "            #Appy interp function to coords in each direction\n",
    "            for direct in u2_dirlist:\n",
    "                coords_use = np.stack((coords_dist.loc[i, (slice(None), direct, 'x')].values,\n",
    "                                       coords_dist.loc[i, (slice(None), direct, 'y')].values)).T\n",
    "                interped_dat.loc[i, idx[:, direct]] = interpfunction(coords_use)\n",
    "            \n",
    "    return interped_dat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6052fe-40be-47c5-96bb-5bcb57ecd2bc",
   "metadata": {},
   "source": [
    "## Gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2819b791-eaee-4593-af30-520aef31a0ce",
   "metadata": {},
   "source": [
    "### NSEW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b5c07070-b465-492b-9e63-766c1041ffa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gradient calcs\n",
    "\n",
    "def NSEWgradcalc(hrz_wind, interpdat, dtindex, nancount, nanmask, varlist, levlist,\n",
    "                 interpdist = 1000, kernel = 'thin_plate_spline'):\n",
    "    \n",
    "    #Calc coords of interp locations\n",
    "    coords_dist = NSEWcoords(interpdist)\n",
    "    \n",
    "    #Create output grad df\n",
    "    grad_updown = make_multi_df([varlist, levlist, towlist], ['var', 'lev', 'tow'], dtindex)    \n",
    "    \n",
    "    \n",
    "    for var in varlist: #Loop through variable\n",
    "        for lev in levlist: #Loop through all three levels\n",
    "            data_use = interpdat[var][lev]\n",
    "            pointdat = interp_NSEW(data_use, coords_dist, dtindex, nancount[var][lev], nanmask[var][lev], \n",
    "                                   kernel) #gradients for particular var, lev, \n",
    "            grad_NSEW = NSEW_point_to_grad(pointdat, dtindex, interpdist)\n",
    "            grad_updown[var, lev] = grad_NSEW_to_updown(hrz_wind, grad_NSEW)\n",
    "           \n",
    "    \n",
    "    return grad_updown\n",
    "\n",
    "\n",
    "#Converts point data to gradients\n",
    "def NSEW_point_to_grad(pointdat, dtindex, dist):\n",
    "    grad = pd.DataFrame(index = dtindex, columns = towc2dir_cols)\n",
    "    grad.loc[:, (slice(None), 'NS')] = \\\n",
    "    (pointdat.loc[:, (slice(None), 'N')].values - pointdat.loc[:, (slice(None), 'S')].values)/(2*dist)\n",
    "    grad.loc[:, (slice(None), 'EW')] = \\\n",
    "    (pointdat.loc[:, (slice(None), 'E')].values - pointdat.loc[:, (slice(None), 'W')].values)/(2*dist)\n",
    "\n",
    "    return grad\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "484f3a21-5c06-4a99-a813-9c17b5425f3e",
   "metadata": {},
   "source": [
    "### Up/down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e771300-dcb7-4f33-99b0-0bc6e621baef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Updown calcs\n",
    "\n",
    "def updowngradcalc(hrz_wind, interpdat, dtindex, nancount, nanmask, varlist, levlist,\n",
    "                   interpdist = 1000, kernel = 'thin_plate_spline'):\n",
    "    \n",
    "    #Coordinates for points up and downwind of towers\n",
    "    coords_dist = updowncoords(interpdist, hrz_wind['WD'].astype(float))\n",
    "    \n",
    "    #Set up df to receive grad data\n",
    "    grad_updown = make_multi_df([varlist, levlist, towlist], ['var', 'lev', 'tow'], dtindex)\n",
    "    \n",
    "    for var in varlist: #Loop through variable\n",
    "        for lev in levlist: #Loop through all three levels\n",
    "            data_use = interpdat[var][lev]\n",
    "            pointdat = interp_updown(data_use, coords_dist, dtindex, nancount[var][lev], nanmask[var][lev],\n",
    "                                     kernel) #gradients for particular var, lev, all tow, dirs\n",
    "            grad_updown[var, lev] = updown_point_to_grad(pointdat, dtindex, interpdist)\n",
    "    \n",
    "    \n",
    "    return grad_updown \n",
    "\n",
    "\n",
    "\n",
    "#Converts point data to gradients #fixthis1\n",
    "def updown_point_to_grad(pointdat, dtindex, dist):\n",
    "    grad_dat = (pointdat.loc[:, (slice(None), 'up')].values - pointdat.loc[:, (slice(None), 'down')].values)/(2*dist)\n",
    "    grad = pd.DataFrame(index = dtindex, columns = towlist, data = grad_dat)\n",
    "    return grad\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e374b209-57bd-4472-b583-b3981d2d8fb0",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "### Weighted Gradient Averaging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "00bad3fa-6f98-4d1f-b812-22755698b126",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_averaging(hrz_wind, interpdat, dtindex, tc, varlist, levlist):\n",
    "    #Calculated gradients for each var, lev, tow, NS/EW\n",
    "    grad_updown = make_multi_df([varlist, levlist, towlist], ['var', 'lev', 'tow'], dtindex)\n",
    "    grad_calc = make_multi_df([varlist, levlist, towlist, c2_dirlist], ['var', 'lev', 'tow', 'direct'], dtindex)\n",
    "    #Distance between each pair of towers\n",
    "\n",
    "    #Loop through each tower\n",
    "    for tow1 in towlist: #Tower that we want to calc gradietnts for\n",
    "        #Create data frame to calc gradients between each pair of towers, to be averaged   \n",
    "\n",
    "        for var in varlist: #Loop through variable\n",
    "            for lev in levlist: #Loop through all three levels\n",
    "                data_use = interpdat[var][lev]\n",
    "                gradx, grady = one_tow_grad_avg(tow1, data_use, tc)\n",
    "                grad_updown[var, lev, tow1] = one_tow_grad_NSEW_to_updown(hrz_wind, tow1, gradx, grady)\n",
    "    return grad_updown"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fafc61e8-06bb-40dd-93c2-b5e6862d50a5",
   "metadata": {},
   "source": [
    "#### one_tow_grad_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ff692b22-3302-4624-8a53-2e0f481a6186",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_tow_grad_avg(tow1, data_use, tc):\n",
    "\n",
    "    sum_weights = np.zeros(len(dtindex))\n",
    "    gradx_sum = np.zeros(len(dtindex))\n",
    "    grady_sum = np.zeros(len(dtindex))\n",
    "    \n",
    "\n",
    "    for tow2 in towlist:\n",
    "        hrz_dists = pd.DataFrame(columns = towlist)\n",
    "        if tow1 == tow2: #No need to compare to same tower\n",
    "            pass\n",
    "        else:\n",
    "            deltax = tc.loc[tow1].x - tc.loc[tow2].x #x distance between two towers\n",
    "            deltay = tc.loc[tow1].y - tc.loc[tow2].y #y distance between two towers\n",
    "            hrz_dists = (deltax**2 + deltay**2)**(1/2) #Total horizontal distance between towers\n",
    "            weight = 1/hrz_dists \n",
    "\n",
    "            delta_var = data_use[tow1] - data_use[tow2] #Difference in var from tow1 to tow2\n",
    "            grad_var = delta_var/(np.abs(deltax) + np.abs(deltay)) #assuming same grad in x and y dirs\n",
    "            gradx = np.nan_to_num(grad_var*deltax/np.abs(deltax)*weight) #need sign of deltax and y\n",
    "            grady = np.nan_to_num(grad_var*deltay/np.abs(deltay)*weight) #need sign of deltax and y\n",
    "            gradx_sum = gradx_sum + gradx\n",
    "            grady_sum = grady_sum + grady\n",
    "\n",
    "            \n",
    "            #Timeseries with weight where gradient is finite, 0 if gradient is nan\n",
    "            time_weights = np.where(np.isfinite(grad_var) == True, weight, 0)\n",
    "            sum_weights = sum_weights + time_weights #Add up weights for each tower\n",
    "\n",
    "    sum_weights = np.where(sum_weights > 0, sum_weights, np.nan) #If sum_weights is 0, set to nan\n",
    "    gradx_mean = gradx_sum/sum_weights\n",
    "    grady_mean = grady_sum/sum_weights\n",
    "    \n",
    "    \n",
    "    \n",
    "    return gradx_mean, grady_mean\n",
    "    \n",
    "\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bfb16ef-c125-4dac-bb2a-621425309710",
   "metadata": {},
   "source": [
    "#### one_tow_grad_NSEW_to_updown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dfe86fcc-eed7-406c-9762-921fb5fd93a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for NSEW gradients to updown, one tower at a time, just for gradient averaging method    \n",
    "def one_tow_grad_NSEW_to_updown(hrz_wind, tow, EW_grad, NS_grad):\n",
    "    WD_rad = hrz_wind['WD'][tow]*np.pi/180 #Convert to radians\n",
    "    grad_updown = NS_grad*np.cos(WD_rad.astype(float)) + EW_grad*np.sin(WD_rad.astype(float))\n",
    "    return grad_updown    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5d5ad7-976d-44b6-a115-8f922cd2c49e",
   "metadata": {},
   "source": [
    "## Wind Dat Calc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2c59b490-f29c-42bf-99d0-473da6063e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This only changes for stability method, otherwise is same for all cases\n",
    "#Currently calculating wind speed at 33 m for all towers regardless of z1. Could just use WS_top for z1>30\n",
    "\n",
    "def U_33_calc(stab_meth, MO, hrz_wind):\n",
    "    WS_33 = pd.DataFrame(index = dtindex, columns = towlist)\n",
    "    \n",
    "    \n",
    "    for tow in towlist:\n",
    "        \n",
    "        #Tower constants\n",
    "        h_veg = tc.veg_h.loc[tow] #vegetation height\n",
    "        z_Umes= tc.z1.loc[tow] #Wind measurement height\n",
    "        z0 = 0.1*h_veg #friction parameter\n",
    "        z0_soil = 0.006 #From biophysic notes, check book Table_, ch.5\n",
    "        d = tc.d.loc[tow] #zero plane displacement\n",
    "        a = 1 #From Campbell and Norman table 5.2 for Larch trees\n",
    "        \n",
    "        Psi_Umes = stab_cor(stab_meth, z_Umes, z0, MO[tow], dtindex)\n",
    "        ustar_calc = hrz_wind['WS_top'][tow]*k/np.log((z_Umes - d)/z0 + Psi_Umes) #ustar to use in wind profile\n",
    "        u_of_h = ustar_calc/k*np.log((h_veg-d)/z0) #Wind speed at top of canopy\n",
    "        u_of_soil = u_of_h*np.exp(a*(z0/h_veg - 1)) #WS at 0.1h, using exponential sub-canopy model\n",
    "        ustar_soil = u_of_soil*k/np.log(z0/z0_soil) #Soil friction velocity, calculated from WS at 01.h\n",
    "        \n",
    "\n",
    "        z = 33 #Get wind speed at 33 m for all towers\n",
    "\n",
    "        WS_33[tow] = WS_of_z(stab_meth, z, z0, d, h_veg, z0_soil, u_of_h, ustar_calc, ustar_soil, MO[tow], dtindex)\n",
    "        \n",
    "        \n",
    "        #Dataframe to hold u and v\n",
    "    U_33 = make_multi_df([U_varlist, U_levlist, towlist], ['var', 'lev', 'tow'], dtindex)\n",
    "\n",
    "    #Calculate u and v from WD - currently at top for each tower\n",
    "    WD_rad = hrz_wind['WD']*np.pi/180 #Convert to radians\n",
    "    U_33['u', 33] = WS_33*-np.sin(WD_rad.astype(float))\n",
    "    U_33['v', 33] = WS_33*-np.cos(WD_rad.astype(float))\n",
    "\n",
    "    stab_meth_old = stab_meth\n",
    "    return U_33"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faafb81a-b04d-4033-a8fb-e79d57e5fcc5",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "# Setup for this notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c4efd8-c99d-453f-8a06-e95e95f4b232",
   "metadata": {},
   "source": [
    "## Read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "25b93730-9bfa-462a-b143-ecaed446632a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in data \n",
    "startdate = dt.datetime(2019, 6, 20)\n",
    "enddate = dt.datetime(2019, 10, 13, 23, 30)\n",
    "# startdate = dt.datetime(2019, 7, 1)\n",
    "# enddate = dt.datetime(2019, 7, 2)\n",
    "\n",
    "dtindex = readdata('dtindex', startdate, enddate) #Save dtindex as separate variable\n",
    "hrz_wind = readdata('hrz_wind', startdate, enddate) #Create function to set this if I try different hrz_wind calcs #fixthis\n",
    "tracdat = {'TA': readdata('TA', startdate, enddate),\n",
    "              'H2O': readdata('H2O', startdate, enddate)} #data to be inerpolated\n",
    "MO = readdata('MO', startdate, enddate)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e87b5d-b0f1-4b98-902c-dcd7aad307dc",
   "metadata": {},
   "source": [
    "## Interpolation setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9385c734-8c93-4010-aed0-683efcfd8719",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make a 2D array with x and y values for location of each tower used for interpolation\n",
    "ar = np.array([tc.x.values, tc.y.values]).T\n",
    "\n",
    "#nancount and mask for tracer data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "43d94bfb-b314-4ab8-bfc0-db5f6b3955e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Creat nanmask and nancount arrays\n",
    "nanmask, nancount = nancounts(tracdat, trac_varlist, trac_levlist)\n",
    "nanmask.to_pickle(intermed_filepath + 'nandat/trac_nanmask.pickle')\n",
    "nancount.to_pickle(intermed_filepath + 'nandat/trac_nancount.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "168916cd-3c23-444f-97cf-b936295ea399",
   "metadata": {},
   "source": [
    "# Run interpolation - T and q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a6981d-518a-4492-a3e8-9eaaea3490f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# kernel = 'thin_plate_spline'\n",
    "step = 0.1 #Step for vertical integration\n",
    "save = True\n",
    "interpdat = tracdat\n",
    "varlist, levlist = trac_varlist, trac_levlist\n",
    "\n",
    "\n",
    "\n",
    "for case in cases.index:\n",
    "    #Case parameters\n",
    "    grad_method = cases['grad_method'].loc[case]\n",
    "    interpdist = cases['interp_dist'].loc[case]\n",
    "    interpdir = cases['interp_dir'].loc[case]\n",
    "    stab_meth = cases['stability'].loc[case]\n",
    "    kernel = cases['interp_kernel'].loc[case]\n",
    "    \n",
    "        \n",
    "    ##Creat nanmask and nancount arrays\n",
    "    nanmask, nancount = nancounts(interpdat, varlist, levlist)\n",
    "    \n",
    "    #Run interpolation\n",
    "    if grad_method == 'gradavg':\n",
    "        grad_updown = gradient_averaging(hrz_wind, interpdat, dtindex, tc, varlist, levlist)\n",
    "        filepath = intermed_filepath + 'hrz_gradients/'+ grad_method + '.pickle'\n",
    "        \n",
    "    elif grad_method == 'interp':\n",
    "        if interpdir == 'NSEW':\n",
    "            grad_updown = NSEWgradcalc(hrz_wind, interpdat, dtindex, nancount, nanmask, \n",
    "                                       varlist, levlist, interpdist, kernel)\n",
    "        elif interpdir == 'updown':\n",
    "            grad_updown = updowngradcalc(hrz_wind, interpdat, dtindex, nancount, nanmask, \n",
    "                                         varlist, levlist, interpdist, kernel)\n",
    "        filepath = intermed_filepath + 'hrz_gradients/tracer' + grad_method + str(interpdist) + interpdir + kernel + '.pickle'\n",
    "    \n",
    "    # # Filepath for shortened time\n",
    "    filepath = intermed_filepath + 'hrz_gradients/tracer' + grad_method + str(interpdist) + str(interpdir) \\\n",
    "     + str(kernel) +str(stab_meth) + startdate.strftime(\"%m%d\")+ '-'+ enddate.strftime(\"%m%d\")+'.pickle'\n",
    "    \n",
    "    if save == True:\n",
    "        with open(filepath, 'wb') as handle:\n",
    "            pickle.dump(grad_updown, handle)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd0b2d6-bb7a-4e89-ab18-60c6e1efa48b",
   "metadata": {},
   "source": [
    "# Calc Vertical Velocity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "212fe2ec-e10a-41e9-b2cf-04304b067091",
   "metadata": {},
   "source": [
    "## Wind Interpolation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f954973a-057b-4af0-aa56-8eca2b6eefc0",
   "metadata": {},
   "source": [
    "### Setup and get wind data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b6929443-9bd0-40f1-9376-7731d7f01a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "stab_meth = None#'Benoit'\n",
    "interpdist = 1000\n",
    "kernel = 'thin_plate_spline'\n",
    "step = 0.1\n",
    "z_mes = 33 #Height of interpolated wind data\n",
    "\n",
    "\n",
    "#calc U_33\n",
    "U_33 = U_33_calc(stab_meth, MO, hrz_wind)\n",
    "\n",
    "#Calc coords of interp locations\n",
    "coords_dist = NSEWcoords(interpdist)\n",
    "\n",
    "##Creat nanmask and nancount arrays\n",
    "nanmask, nancount = nancounts(U_33, U_varlist, U_levlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "908db674-792a-4f81-b467-3f78591a1862",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cal U at 33 m at NSEW points\n",
    "pointdat = make_multi_df([U_varlist, U_levlist, towlist, NSEWdirlist], \n",
    "                          ['var', 'lev', 'tow', 'direct'], dtindex)    \n",
    "\n",
    "\n",
    "for var in U_varlist: #Loop through variable\n",
    "    for lev in U_levlist: #Only on level, matching format for tracer interp\n",
    "        data_use = U_33[var][lev]\n",
    "        pointdat[var, lev] = interp_NSEW(data_use, coords_dist, dtindex, nancount[var][lev], nanmask[var][lev], \n",
    "                               kernel) #gradients for particular var, lev, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b9ae9ee4-ede3-43b5-a270-afee93737fe6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "w_cont = pd.DataFrame(columns = towlist, index = dtindex)\n",
    "\n",
    "for tow in towlist:\n",
    "    u_E = wind_prof(tow, stab_meth, pointdat.loc[:, ('u', 33, tow, 'E')], MO[tow], dtindex,\n",
    "                    step, z_mes)\n",
    "    u_W = wind_prof(tow, stab_meth, pointdat.loc[:, ('u', 33, tow, 'W')], MO[tow], dtindex,\n",
    "                    step, z_mes)\n",
    "    v_N = wind_prof(tow, stab_meth, pointdat.loc[:, ('v', 33, tow, 'N')], MO[tow], dtindex,\n",
    "                    step, z_mes)\n",
    "    v_S = wind_prof(tow, stab_meth, pointdat.loc[:, ('v', 33, tow, 'S')], MO[tow], dtindex,\n",
    "                    step, z_mes)\n",
    "    \n",
    "    dudx = (u_E - u_W)/(2*interpdist) #positive sign is divergence, neg convergence\n",
    "    dvdy = (v_N - v_S)/(2*interpdist) #positive sign is divergence, neg convergence\n",
    "    dwdz = -dudx - dvdy\n",
    "    w_cont[tow] = dwdz.sum(axis = 1)\n",
    "    \n",
    "# save w_cont to inputs\n",
    "w_cont.to_pickle(input_filepath + 'w_cont_lai.pickle')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2306b2d-1f52-4c45-916d-2c34896fc704",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Move all this into different notebook later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a492f8-020e-494e-856b-2f025ed5eedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_son = readdata('w_son', startdate, enddate) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50581d9c-81cb-4565-9ddb-dbe734da76b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 5\n",
    "m = 9\n",
    "\n",
    "cut_startdate = dt.datetime(2019, m, d )\n",
    "cut_enddate = dt.datetime(2019, m, d + 5)\n",
    "w_cont_cut = w_cont.loc[cut_startdate:cut_enddate]\n",
    "w_son_cut = w_son.loc[cut_startdate:cut_enddate]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a7389d-c335-4056-94a2-bec1b5eabed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_son_nonan = w_son.dropna(subset=['PFb', 'PFc']).astype('float')\n",
    "\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(w_son_nonan['PFb'], w_son_nonan['PFc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e8affb-4bdc-4136-9a1c-0437ed6a5e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05bd64b4-2cd9-4c31-8988-c496df075f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(-0.5, 0.8, 0.1)\n",
    "y = x*slope + intercept\n",
    "\n",
    "\n",
    "plt.scatter(w_son_nonan['PFb'], w_son_nonan['PFc'], s = 1)\n",
    "\n",
    "plt.plot(x, y, color = \"xkcd:terracotta\", linewidth = 1.5)\n",
    "\n",
    "# Get current axes\n",
    "ax = plt.gca()\n",
    "\n",
    "# # Set the position of the spines to cross at (0,0)\n",
    "# ax.spines['left'].set_position('zero')\n",
    "# ax.spines['bottom'].set_position('zero')\n",
    "\n",
    "# # Hide the top and right spines\n",
    "# ax.spines['right'].set_color('none')\n",
    "# ax.spines['top'].set_color('none')\n",
    "\n",
    "ax.grid(True, which='both')\n",
    "\n",
    "# ax.set_xlabel('nw1 w [m/s]', labelpad= -30, ha='right', x=0.97)\n",
    "# ax.set_ylabel('nw2 w [m/s]', labelpad=-30, va='top', y=1.05, rotation = 0 )\n",
    "\n",
    "ax.set_xlabel('nw1 w [m/s]')\n",
    "ax.set_ylabel('nw2 w [m/s]')\n",
    "plt.tight_layout()\n",
    "\n",
    "# plt.xlabel('w nw1 [m/s]')\n",
    "# plt.ylabel('w nw2 [m/s]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34585080-f9fe-4ca3-8ab9-ea7ac07f0249",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.gca()\n",
    "ax.axhline(y=0, color='gray', linestyle='--', linewidth=1)\n",
    "for tow in towlist[1:5]:\n",
    "    plt.plot(w_son_cut[tow], label = tc.loc[tow].wind_var[-3:])\n",
    "plt.xticks(rotation = 45);\n",
    "plt.legend();\n",
    "plt.ylabel('w [m/s]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a515ebb-54ad-4596-abbd-17a06706559a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tc.loc['PFb']['org_path']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1f9455-c8cd-4e44-9fbe-685aefeecdfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.gca()\n",
    "ax.axhline(y=0, color='gray', linestyle='--', linewidth=1)\n",
    "\n",
    "plt.plot(w_son_cut['PFb'], label = 'nw1 w sonic')\n",
    "plt.plot(w_cont_cut['PFb'], label = 'nw1 w continuity')\n",
    "plt.plot(w_son_cut['PFc'], label = 'nw2 w sonic')\n",
    "plt.plot(w_cont_cut['PFc'], label = 'nw2 w continuity')\n",
    "plt.xticks(rotation = 45);\n",
    "plt.legend();\n",
    "plt.ylabel('w [m/s]')\n",
    "\n",
    "# ax = plt.gca()\n",
    "# ax.axhline(y=0, color='gray', linestyle='--', linewidth=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da3dc02-4e90-4558-9156-8fee511d199b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(w_son['PFb'], w_son['PFc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750e532a-a6e2-4740-a407-355819424f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tow = 'PFb'\n",
    "fig, ax1 = plt.subplots()\n",
    "plt.plot(w_cont_cut[tow], label = 'continuity');\n",
    "plt.plot(-w_son_cut[tow], label = 'sonic');\n",
    "# ax2 = ax1.twinx()\n",
    "# ax2.plot(WD_cut[tow], label = 'wind dir', color = 'k')\n",
    "fig.legend()\n",
    "plt.title(tow)\n",
    "plt.ylabel('w_cont, w_son')\n",
    "# plt.ylabel('w [m/s]')\n",
    "plt.xticks(rotation = 45);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ae5efc-361a-41b3-bcb0-8b1fa8227287",
   "metadata": {},
   "outputs": [],
   "source": [
    "h = 7\n",
    "lag_list = np.arange(-6, 6)\n",
    "corr = pd.DataFrame(index = towlist, columns = lag_list)\n",
    "for lag in lag_list:\n",
    "    cut1_startdate = dt.datetime(2019, 6, 21, h)\n",
    "    cut1_enddate = dt.datetime(2019, 10, 13, h)\n",
    "    cut2_startdate = dt.datetime(2019, 6, 21, h+lag)\n",
    "    cut2_enddate = dt.datetime(2019, 10, 13, h+lag)\n",
    "    w_cont_cut = w_cont.loc[cut1_startdate:cut1_enddate]\n",
    "    w_son_cut = w_son.loc[cut2_startdate:cut2_enddate]\n",
    "    for tow in towlist[1:]:\n",
    "        x, y = w_son_cut[tow].values.astype('float'), w_cont_cut[tow].values.astype('float')\n",
    "        nas = np.logical_or(np.isnan(x), np.isnan(y))\n",
    "        corr.loc[tow, lag] = scipy.stats.pearsonr(x[~nas], y[~nas])[0]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bea2856-d66f-4244-bbb5-3a9b6e93777c",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = pd.Series(index = towlist)\n",
    "for tow in towlist[1:]:\n",
    "    x, y = w_son_cut[tow].values.astype('float'), w_cont_cut[tow].values.astype('float')\n",
    "    nas = np.logical_or(np.isnan(x), np.isnan(y))\n",
    "    corr.loc[tow] = scipy.stats.pearsonr(x[~nas], y[~nas])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041fff92-6aec-48ef-818a-7b36d00f11b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e708b277-5a0b-4c3d-b599-784813ee8122",
   "metadata": {},
   "outputs": [],
   "source": [
    "#color list\n",
    "colorlist = [\"xkcd:ocean blue\", \"xkcd:terracotta\", \"xkcd:blue green\",\"xkcd:grape\",  \"xkcd:grey\",  \n",
    "             \"xkcd:forrest green\",\"xkcd:magenta\", \"xkcd:grey blue\", \"xkcd:dark yellow\",\"xkcd:coral\",\n",
    "              \"xkcd:sky blue\", \"xkcd:light orange\",\"xkcd:reddish brown\", \"xkcd:dark lavender\",  \"xkcd:light olive\",\n",
    "             \"xkcd:puke yellow\", \"xkcd:light cyan\", \"xkcd:orchid\",  \"xkcd:periwinkle blue\"]\n",
    "mpl.rcParams['axes.prop_cycle'] = mpl.cycler(color=colorlist) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1737cb97-62df-4ea1-9629-04b7d65bf32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter = plt.scatter(tc.x, tc.y, c=corr, cmap='PuOr')\n",
    "plt.colorbar(scatter, label='Value')\n",
    "plt.xlabel('x [m]')\n",
    "plt.ylabel('y [m]')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd54980-3f22-4c9d-855e-e49229d855c0",
   "metadata": {},
   "source": [
    "# Archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9092e694-5c84-4713-98b6-6d9e8aca68a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tow = 'PFA'\n",
    "# WS_use_tow = pointdat.loc[:, ('u', 33, tow, 'E')]\n",
    "# #Tower constants\n",
    "# step = 0.1\n",
    "# h_veg = tc.veg_h.loc[tow] #vegetation height\n",
    "# z_son = round(tc.z_son.loc[tow], 1) #tower height, rounded to nearest 0.1, don't actually need this now but in case of use with more precise heights\n",
    "# z_range = np.arange(0, z_son + step, step) #need wind profile up to level of sonic\n",
    "# z_Umes = 33\n",
    "# z0 = 0.1*h_veg #friction parameter\n",
    "# z0_soil = 0.006 #From biophysic notes, check book Table_, ch.5\n",
    "# d = tc.d.loc[tow] #zero plane displacement\n",
    "# a = a_default #Attenuation coeficient\n",
    "\n",
    "# WS_prof = pd.DataFrame(index = dtindex, columns = z_range) #windspeed profile\n",
    "\n",
    "# Psi_z1 = stab_cor(stab_meth, z_Umes, z0, MO[tow], dtindex)\n",
    "# ustar_calc = WS_use_tow*k/np.log((z_Umes - d)/z0 + Psi_z1) #ustar to use in wind profile\n",
    "# u_of_h = ustar_calc/k*np.log((h_veg-d)/z0) #Wind speed at top of canopy\n",
    "# u_of_soil = u_of_h*np.exp(a*(z0/h_veg - 1)) #WS at 0.1h, using exponential sub-canopy model\n",
    "# ustar_soil = u_of_soil*k/np.log(z0/z0_soil) #Soil friction velocity, calculated from WS at 01.h\n",
    "    \n",
    "    \n",
    "# WS_of_z(stab_meth, h, z0, d, h_veg, z0_soil, u_of_h, ustar_calc, ustar_soil, MO[tow], dtindex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8851cc5-e299-4982-8f3b-0d4c4d44cccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# timestamp = dtindex[0]\n",
    "# TA_2 = interpdat['TA'].loc[2, timestamp]\n",
    "# plt.tricontourf(tc.x, tc.y, TA_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d79797b-f1b8-45b6-8a95-5717d4a281ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check updown coords visually\n",
    "\n",
    "# WD = readdata('hrz_wind', startdate, enddate).loc['WD']\n",
    "# ud_coords = updowncoords(0.5, WD)\n",
    "\n",
    "# timestep = 320 #Angle (1 degree +1 per timestamp)\n",
    "\n",
    "# up_x = ud_coords.loc[ud_coords.index[timestep], (slice(None), 'up', 'x')].values\n",
    "# up_y = ud_coords.loc[ud_coords.index[timestep], (slice(None), 'up', 'y')].values\n",
    "\n",
    "# down_x = ud_coords.loc[ud_coords.index[timestep], (slice(None), 'down', 'x')].values\n",
    "# down_y = ud_coords.loc[ud_coords.index[timestep], (slice(None), 'down', 'y')].values\n",
    "\n",
    "# plt.scatter(tc.x, tc.y)\n",
    "# plt.scatter(up_x, up_y)\n",
    "# plt.scatter(down_x, down_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b924fa10-d109-4dbf-a1db-350f9166269b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Create dtindex file in case I mess it up again\n",
    "\n",
    "# dtindex = hrz_wind.loc['WD'].index\n",
    "\n",
    "# #Filepath for full time\n",
    "# filepath = '../Inputs/dtindex.pickle'\n",
    "\n",
    "# with open(filepath, 'wb') as handle:\n",
    "#     pickle.dump(dtindex, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04597c5a-890d-4c72-83b5-e19a384b2b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save all interp coords (rather than calculating separately for each run)\n",
    "# coords = {}\n",
    "# coords['NSEW'] = {}\n",
    "# coords['updown'] = {}\n",
    "\n",
    "# for dist in distlist: \n",
    "#     coords['NSEW'][dist] = NSEWcoords(dist) #Nested dictionary - [distance][direction] - 2 cols (x and y coords)\n",
    "#     coords['updown'][dist] = updowncoords(dist, unidata, tc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fcfa154-a1bb-417b-ba8c-94f62726814e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Interpolate to up and downwind points, rather than N/S, E/W points\n",
    "# x_up =  pd.DataFrame(index=df_TA.index)\n",
    "# x_down =  pd.DataFrame(index=df_TA.index)\n",
    "# y_up =  pd.DataFrame(index=df_TA.index)\n",
    "# y_down =  pd.DataFrame(index=df_TA.index)\n",
    "# for tower in tc.index:\n",
    "# #     x_coord[str(tower + '_up')] = tc['x'][tower] + np.cos(PFA_interp.WD_1_1_1*np.pi/180)\n",
    "# #     x_coord[str(tower + '_down')] = tc['x'][tower] - np.cos(PFA_interp.WD_1_1_1*np.pi/180)\n",
    "    \n",
    "# #     y_coord[str(tower + '_up')] = tc['y'][tower] + np.sin(PFA_interp.WD_1_1_1*np.pi/180)\n",
    "# #     y_coord[str(tower + '_down')] = tc['y'][tower] - np.sin(PFA_interp.WD_1_1_1*np.pi/180)\n",
    "    \n",
    "    \n",
    "#     x_up[tower] = tc['x'][tower] + np.cos(PFA_interp.WD_1_1_1*np.pi/180)\n",
    "#     x_down[tower] = tc['x'][tower] - np.cos(PFA_interp.WD_1_1_1*np.pi/180)\n",
    "    \n",
    "#     y_up[tower] = tc['y'][tower] + np.sin(PFA_interp.WD_1_1_1*np.pi/180)\n",
    "#     y_down[tower] = tc['y'][tower] - np.sin(PFA_interp.WD_1_1_1*np.pi/180)\n",
    "    \n",
    "    \n",
    "# #Interpolate to up and downwind coords (comment this section!)\n",
    "\n",
    "# #Make a 2D array with x and y values for location of each tower\n",
    "# ar = np.array([tc.y.values, tc.x.values]).T\n",
    "\n",
    "# #3D arrays of locations 1km up and down wind of each tower \n",
    "# #Dims are tower, time, and direction (x/y)\n",
    "# up_coords = np.stack((np.asarray(x_up), np.asarray(y_up))).T\n",
    "# down_coords = np.stack((np.asarray(x_down), np.asarray(y_down))).T\n",
    "\n",
    "\n",
    "# #Initiate lists to recieve up and downwind temperatures\n",
    "# T_i_up = []\n",
    "# T_i_down = []\n",
    "\n",
    "# #Loop through each time stamp and interpolate to up and downwind coordinates\n",
    "# #Is there a way to do this without a for loop - not sure since the coords change with each time step\n",
    "# #It doesn't take too long as is so maybe fine this way\n",
    "# #Could use points N/S, E/W of towers, use x and y components of velocity\n",
    "# for i in range(len(df_TA)):\n",
    "#     T_i_up.append(RBFInterpolator(ar, df_TA.values.T[:, i])(up_coords[:, i, :]))\n",
    "#     T_i_down.append(RBFInterpolator(ar, df_TA.values.T[:, i])(down_coords[:, i, :]))\n",
    "\n",
    "    \n",
    "# #Convert lists to arrays\n",
    "# T_i_up = np.asarray(T_i_up)\n",
    "# T_i_down = np.asarray(T_i_down)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e989e0f-cc39-4a47-80fb-e98fd4b1717e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot profiles \n",
    "\n",
    "# #profile_plot(30_m_data, 10_m_data, 2_m_data, folder_for_plot_storage, x_axis_range)\n",
    "\n",
    "# def profile_plot(data_1, data_2, data_3, folder, x_range = [-4, 4]):\n",
    "#     data_mon_1 = data_1.groupby([data_1.index.month, data_1.index.time]).mean()\n",
    "#     data_mon_2 = data_2.groupby([data_2.index.month, data_2.index.time]).mean()\n",
    "#     data_mon_3 = data_3.groupby([data_3.index.month, data_3.index.time]).mean()\n",
    "    \n",
    "    \n",
    "    \n",
    "#     for tower in tc.index:\n",
    "        \n",
    "#         if towdat.z3 == 0:\n",
    "#             pass\n",
    "        \n",
    "#         else:\n",
    "\n",
    "#             fig, axs = plt.subplots(12, 4, figsize = (10, 30))\n",
    "#             for mon in range(6, 11):\n",
    "#                 i=0\n",
    "#                 for hour in data_mon_1.index.get_level_values(1).drop_duplicates():\n",
    "#                     ax = axs[i//4, i%4]\n",
    "#                     i= i+1\n",
    "                    \n",
    "#                     dif_top = data_mon_1.loc[(mon, hour), tower] - data_mon_2.loc[(mon, hour), tower]\n",
    "#                     dif_bottom = data_mon_3.loc[(mon, hour), tower] - data_mon_2.loc[(mon, hour), tower]\n",
    "#                     # dif_bottom = data_mon[mon][hour][tower] - data_mon[mon][hour]tower]\n",
    "\n",
    "#                     # ax.plot([df_mon.TA_1_1_1[mon][hour], df_mon.TA_1_2_1[mon][hour],df_mon.TA_1_3_1[mon][hour]], [towdat.z1, towdat.z2, towdat.z3])\n",
    "#                     ax.plot([dif_top, 0, dif_bottom], [towdat.z1, towdat.z2, towdat.z3])\n",
    "#                     ax.set_yticks([towdat.z3, towdat.z2, towdat.z1])\n",
    "#                     ax.set_title(hour)\n",
    "#                     ax.set_xlim(x_range)\n",
    "\n",
    "#             fig.suptitle(tower)\n",
    "#             plt.tight_layout()\n",
    "#             plt.savefig(str('./Outputs/diff_Profiles/Interp_dirs/' + folder + '/' +tower + '_TA_diff_profiles'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcede11f-6403-42ef-ad36-84940fe7619e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Calc horizontal distances between each pair of towers\n",
    "# hrz_dists = pd.DataFrame(index = towlist, columns = towlist)\n",
    "# #For each tow1, loop through other towers to calc gradients between them\n",
    "# for tow2 in towlist: #All other towers to calc gradients from\n",
    "#     if tow1 == tow2: #No need to compare to same tower\n",
    "#         pass\n",
    "#     else:\n",
    "#         deltax = tc.loc[tow1].x - tc.loc[tow2].x #x distance between two towers\n",
    "#         deltay = tc.loc[tow1].y - tc.loc[tow2].y #y distance between two towers\n",
    "#         hrz_dists.loc[tow2, tow1] = (deltax**2 + deltay**2)**(1/2) #Total horizontal distance between towers"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
